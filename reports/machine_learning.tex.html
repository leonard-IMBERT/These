<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>TeXtidote analysis</title>
<style type="text/css">
body {
  font-family: sans-serif;
}
.highlight, .highlight-sh, .highlight-spelling {
  padding: 2pt;
  border-radius: 4pt;
  cursor: help;
  opacity: 0.7;
  border: dashed 1px;
}
.highlight {
  background-color: orange;
  color: black;
}
.highlight-sh {
  background-color: yellow;
  color: black;
}
.highlight-spelling {
  background-color: red;
  color: white;
}
div.original-file {
  font-family: monospace;
  font-size: 11pt;
  background-color: #f8f8ff;
  padding: 20pt;
  border-radius: 6pt;
}
.textidote {
  	background-image: url(data:image/svg+xml;base64,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);
}
h2.filename {
  font-family: monospace;
}
h1.textidote {
  width: 378px;
  height: 68px;
  display: block;
}
.keyword1 {
  font-weight: bold;
  color: green;
}
.keyword2 {
  font-weight: bold;
  color: darkblue;
}
.comment, .comment * {
  color: darkred;
  font-weight: normal;
}
.linenb {
  font-style: italic;
  color: lightgrey;
  width: 30pt;
  float: left;
  margin-top: 1pt;
  margin-bottom: 1pt;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.codeline {
  margin-left: -30pt;
  padding-left: 60pt;
  margin-top: 1pt;
  margin-bottom: 1pt;
}
.no-text {
  display: none;
}
.clear {
  clear: both;
}
</style>
</head>
<body>
<a href="https://sylvainhalle.github.io/textidote"><h1 class="textidote"><span class="no-text">Results of TeXtidote analysis</span></h1></a>
<p>Here is the result of analyzing your file(s) with TeXtidote. Hover the mouse over highlighted portions of the document to read a tooltip that gives you some writing advice.</p>
<p>Found 21 warning(s)</p>
<div class="original-file">
<div class="linenb">&nbsp;&nbsp;1</div><div class="codeline"><span class="keyword1">\documentclass</span>[../main.tex]{subfiles}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;2</div><div class="codeline">\graphicspath{{\subfix{..}}}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;3</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;4</div><div class="codeline"><span class="keyword2">\begin{document}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;5</div><div class="codeline">\chapter{Introduction to the reconstruction methods and algorithms used in this thesis}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;6</div><div class="codeline"><span class="keyword1">\label</span>{sec:ml}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;7</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;8</div><div class="codeline">\epigraph{``I have the shape of a human being and organs equivalent to those of a human being. My organs, in fact, are identical to some of those in a <span class="highlight-spelling" title="Possible spelling mistake found.. Suggestions: [prosthetic, anesthetized, proselytized, phosphatized, posterized, prophesized, prosthetics] (221) [lt:en:MORFOLOGIK_RULE_EN_US]">prosthetized</span> human being. I have contributed artistically, literally, and scientifically to human culture as much as any human being now alive. What more can one ask?''}{<span class="highlight" title="Add a space between sentences.. Suggestions: [ Isaac] (389) [lt:en:SENTENCE_WHITESPACE]">Isaac</span> Asimov, The Complete Robot}</div><div class="clear"></div>
<div class="linenb">&nbsp;&nbsp;9</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">&nbsp;10</div><div class="codeline">\minitoc</div><div class="clear"></div>
<div class="linenb">&nbsp;11</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">&nbsp;12</div><div class="codeline">Machine Learning (ML) and more specifically Neural Network (NN) are families of data-driven algorithms. They are used in a wide variety of domains including natural language processing, computer vision, speech recognition and, the subject of this thesis, scientific studies.</div><div class="clear"></div>
<div class="linenb">&nbsp;13</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">&nbsp;14</div><div class="codeline">Machine learning models aim to learn underlying patterns from finite datasets in order to make general predictions or classifications.</div><div class="clear"></div>
<div class="linenb">&nbsp;15</div><div class="codeline">For example, in our case, it could be an algorithm that would differentiate the nature of a particle interacting in the liquid scintillator, between a positron and an electron, based on the readout charge and time $(Q, t)$ of the 17612 LPMT of the JUNO experiment. During a first training phase, it would learn the discriminative features between the two in the 35224-dimensional charge and time distribution, built from samples of $e^+$ and $e^-$ events.</div><div class="clear"></div>
<div class="linenb">&nbsp;16</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">&nbsp;17</div><div class="codeline">It extracts essential features from a highly complex and multidimensional dataset that describe the physical interactions: a three body energy deposition (the positron and two annihilation gammas) and the single deposit from an electron.</div><div class="clear"></div>
<div class="linenb">&nbsp;18</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">&nbsp;19</div><div class="codeline">Ideally, the algorithm would learn to recognize this information on its own, regardless of the input size and complexity. In practice, however, these algorithms are guided by human design through their architectures and training conditions. We can still hope that they use more thoroughly the detector information while traditional methods are often subject to assumptions or simplifications to make the task easier (see for instance the algorithm in Section \ref{sec:juno:reco}).</div><div class="clear"></div>
<div class="linenb">&nbsp;20</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">&nbsp;21</div><div class="codeline">The role of machine learning algorithms has expanded rapidly in the past decade, either as the main or secondary algorithm for a wide variety of tasks: event reconstruction, event classification, waveform reconstruction and so on. In particular in domains where the underlying physic and detector processes are complex and highly dimensional, and when large amount of data must be processed quickly.</div><div class="clear"></div>
<div class="linenb">&nbsp;22</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">&nbsp;23</div><div class="codeline">This chapter present an overview of the different kind of machine learning methods and neural networks that will be discussed in this thesis, and the state of the art of the reconstructions methods in JUNO our ML algorithms will be compared to.</div><div class="clear"></div>
<div class="linenb">&nbsp;24</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">&nbsp;25</div><div class="codeline"><span class="keyword1">\section</span>{Core concepts in machine learning and neural networks}</div><div class="clear"></div>
<div class="linenb">&nbsp;26</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">&nbsp;27</div><div class="codeline">In this section, we discuss the core concepts in machine learning that will be used thorough this thesis. We place particular emphasis on Neural Networks, as it's the family of the algorithms described in chapters \ref{sec:jcnn}, \ref{sec:jgnn} and \ref{sec:janne}.</div><div class="clear"></div>
<div class="linenb">&nbsp;28</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">&nbsp;29</div><div class="codeline"><span class="keyword1">\subsection</span>{Boosted Decision Tree (BDT)}</div><div class="clear"></div>
<div class="linenb">&nbsp;30</div><div class="codeline"><span class="keyword1">\label</span>{sec:ml:bdt}</div><div class="clear"></div>
<div class="linenb">&nbsp;31</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">&nbsp;32</div><div class="codeline">One of the most classic machine learning algorithm used in particle physics is Boosted Decision Tree (BDT) \cite{breiman_classification_2017} (or more recently Gradient Boosting Machine \cite{friedman_greedy_2001}).</div><div class="clear"></div>
<div class="linenb">&nbsp;33</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">&nbsp;34</div><div class="codeline">BDTs operate by making a series of decisions based on a set of input features, with each decision represented as a node in the tree.</div><div class="clear"></div>
<div class="linenb">&nbsp;35</div><div class="codeline">Each decision point, or node, takes its decision based on a set of trainable parameters leading to a subtree of decisions. The process is repeated until it reach the final node, yielding the prediction. A simplistic example is given in Figure \ref{fig:ml:bdt}.</div><div class="clear"></div>
<div class="linenb">&nbsp;36</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">&nbsp;37</div><div class="codeline"><span class="keyword2">\begin{figure}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;38</div><div class="codeline">&nbsp;&nbsp;\centering</div><div class="clear"></div>
<div class="linenb">&nbsp;39</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\includegraphics</span>[width=\linewidth]{images/ml/Bdt.jpg}</div><div class="clear"></div>
<div class="linenb">&nbsp;40</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\caption</span>{Example of a BDT that determine if the given object is a duck.}</div><div class="clear"></div>
<div class="linenb">&nbsp;41</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\label</span>{fig:ml:bdt}</div><div class="clear"></div>
<div class="linenb">&nbsp;42</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;43</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">&nbsp;44</div><div class="codeline">The training procedure follows a reward-based approach where the algorithm predictions are compared to the true outcomes.</div><div class="clear"></div>
<div class="linenb">&nbsp;45</div><div class="codeline">During the training phase the prediction of the BDT is compared to a known truth about the data. The score is then used to back-propagate corrections to the parameters of the tree. Modern BDT use gradient boosting where the gradient of the loss is calculated for each of the BDT parameters. Following the gradient descent, we can reach the hopefully global minima of the loss for our set of parameters.</div><div class="clear"></div>
<div class="linenb">&nbsp;46</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">&nbsp;47</div><div class="codeline"><span class="keyword1">\subsection</span>{Artificial Neural Network (NN)}</div><div class="clear"></div>
<div class="linenb">&nbsp;48</div><div class="codeline"><span class="keyword1">\label</span>{sec:ml:nn}</div><div class="clear"></div>
<div class="linenb">&nbsp;49</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">&nbsp;50</div><div class="codeline">One of the modern ML family is the Neural Network, historical name as their design was inspired by the behavior of biological neurons in the brain.</div><div class="clear"></div>
<div class="linenb">&nbsp;51</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[ht]</div><div class="clear"></div>
<div class="linenb">&nbsp;52</div><div class="codeline">&nbsp;&nbsp;\centering</div><div class="clear"></div>
<div class="linenb">&nbsp;53</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\includegraphics</span>[height=6cm]{images/ml/nn_explications.png}</div><div class="clear"></div>
<div class="linenb">&nbsp;54</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\caption</span>{Schema of a simple neural network.}</div><div class="clear"></div>
<div class="linenb">&nbsp;55</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\label</span>{fig:ml:schema_nn}</div><div class="clear"></div>
<div class="linenb">&nbsp;56</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;57</div><div class="codeline">As schematized in Figure \ref{fig:ml:schema_nn}, the input, output and steps inside the NN is described as neuron <span class="keyword1">\textit</span>{layers}. The neurons of the layers take as input a set of values from the preceding layer, here the $a_i$ takes every information of the $x_i$ input layer, and aggregate those values following learnable <span class="keyword1">\textit</span>{parameters} $w_{ij}$. In the example in Figure \ref{fig:ml:schema_nn}, fully connected layers are used, meaning that each neuron in one layer is connected to every neuron in the previous layer.</div><div class="clear"></div>
<div class="linenb">&nbsp;58</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">&nbsp;59</div><div class="codeline">The aggregation procedure is core of defining the architecture of the NN. The different architectures used in this thesis will be discussed in Section \ref{sec:ml:architecture}. The process is repeated until reaching the output layer.</div><div class="clear"></div>
<div class="linenb">&nbsp;60</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">&nbsp;61</div><div class="codeline">For example, let's take the network in Figure \ref{fig:ml:schema_nn} and say that $a_1$, $a_2$ and $a_3$ are the neurons of the output layer. We try to produce a vertex reconstruction algorithm that will approach the charge barycenter. Let's limit the input $x_i$ to the charge of the $i$-th PMT, one of the solution is to aggregate on $a_1$ the $x$ coordinate of the barycenter. The network would thus adapt the $w_{i1}$ parameters<span class="highlight" title="Use a comma before 'so' if it connects two independent clauses (unless they are closely connected and short).. Suggestions: [, so] (5243) [lt:en:COMMA_COMPOUND_SENTENCE]"> so</span> they correspond to the $x$ coordinates of the $i$-th PMT. Same for the $y$ and $z$ coordinate on $a_2$ and $a_3$ respectively.</div><div class="clear"></div>
<div class="linenb">&nbsp;62</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">&nbsp;63</div><div class="codeline">The layers used in the example above are designated as <span class="keyword1">\textit</span>{Fully connected} layers, where every neuron of the layer is connected to the every neuron of the preceding layer. The layer can be expressed using the Einstein summation and in bold the learnable parameters</div><div class="clear"></div>
<div class="linenb">&nbsp;64</div><div class="codeline"><span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;65</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\label</span>{eq:ml:fully-connected-simple}</div><div class="clear"></div>
<div class="linenb">&nbsp;66</div><div class="codeline">&nbsp;&nbsp;O_{j} = I_{i} + \bm{W}_{j}^{i}</div><div class="clear"></div>
<div class="linenb">&nbsp;67</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;68</div><div class="codeline">where $O_{j}$ is the output neurons vector (the $a_i$), $I_{i}$ is the preceding layer neurons vector (the $x_i$) and $\bm{W}$ is the parameters, or weights, matrix (composed of the $w_{ij}$).</div><div class="clear"></div>
<div class="linenb">&nbsp;69</div><div class="codeline">In practice, this fully connected layer is often adjoined a bias $\bm{B}$ and an <span class="keyword1">\textit</span>{activation function} $F$.</div><div class="clear"></div>
<div class="linenb">&nbsp;70</div><div class="codeline"><span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;71</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\label</span>{eq:ml:fully-connected}</div><div class="clear"></div>
<div class="linenb">&nbsp;72</div><div class="codeline">&nbsp;&nbsp;I_{j} = F(I_{i} \bm{W}_{j}^{i} + \bm{B}_j)</div><div class="clear"></div>
<div class="linenb">&nbsp;73</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;74</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">&nbsp;75</div><div class="codeline">This is the fundamental component of the Fully Connected Deep NN (FCDNN) family presented in Section \ref{sec:ml:fcdnn}.</div><div class="clear"></div>
<div class="linenb">&nbsp;76</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">&nbsp;77</div><div class="codeline">This description of neural networks as layers introduce the principles of <span class="keyword1">\textit</span>{depth} and <span class="keyword1">\textit</span>{width}, the number of layers in the NN and the number of neurons in each layer respectively. Those quantities that not directly used for the computation of the results but describes the NN or its training are designated as <span class="keyword1">\textit</span>{hyperparameters}.</div><div class="clear"></div>
<div class="linenb">&nbsp;78</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">&nbsp;79</div><div class="codeline">Now we just need to adapt the parameters so that this network learn that $w_{ij}$ are the PMT coordinate. We describe the space produced by the parameters of the network as the <span class="keyword1">\textit</span>{parameter phase space} or <span class="keyword1">\textit</span>{latent space}. The optimization of the network and exploration of this phase space is done through training over a <span class="keyword1">\textit</span>{training dataset} as described in next section.</div><div class="clear"></div>
<div class="linenb">&nbsp;80</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">&nbsp;81</div><div class="codeline"><span class="keyword1">\subsection</span>{Training procedure}</div><div class="clear"></div>
<div class="linenb">&nbsp;82</div><div class="codeline"><span class="keyword1">\label</span>{sec:ml:train}</div><div class="clear"></div>
<div class="linenb">&nbsp;83</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">&nbsp;84</div><div class="codeline">To adapt the parameters we need an object that describe how well the network perform. This is the <span class="keyword1">\textit</span>{loss} of our neural networks $\mathcal{L}$. In our barycenter example, it could be the distance between the reconstructed and real barycenter. Using this metric we can adjust the parameters of our network.</div><div class="clear"></div>
<div class="linenb">&nbsp;85</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">&nbsp;86</div><div class="codeline">Depending on whether we try to minimize or maximize it, it needs to possess a minimum or a maximum. For example when doing <span class="keyword1">\textit</span>{regression}, i.e.\ produce a scalar result like the coordinates of a barycenter, a common loss is the Mean Square Error (MSE). Let<span class="highlight" title="The personal pronoun 'I' should be uppercase.. Suggestions: [I] (7229) [lt:en:I_LOWERCASE]"> $i$</span> be our dataset, the $N$ events considered for training, $y_i$ be the target scalar, the barycenter positions of each event, $x_i$ the input data, the charge vector, and $f(x_i, \bm{\theta})$ the result of the network. The network here is modelled by $f$, and its parameter $\bm{\theta}$</div><div class="clear"></div>
<div class="linenb">&nbsp;87</div><div class="codeline"><span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;88</div><div class="codeline">&nbsp;&nbsp;\mathcal{L} \equiv MSE = \frac{1}{N} \sum_i^N (y_i - f(x_i, \bm{\theta}))^2</div><div class="clear"></div>
<div class="linenb">&nbsp;89</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;90</div><div class="codeline">Another common loss function is the Mean Absolute Error (MAE)</div><div class="clear"></div>
<div class="linenb">&nbsp;91</div><div class="codeline"><span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;92</div><div class="codeline">&nbsp;&nbsp;\mathcal{L} \equiv MAE = \frac{1}{N} \sum_i^N |y_i - f(x_i, \bm{\theta})|</div><div class="clear"></div>
<div class="linenb">&nbsp;93</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">&nbsp;94</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">&nbsp;95</div><div class="codeline">We see that those loss functions possess a minimum when $f(x_i, \bm{\theta}) = y_i$.</div><div class="clear"></div>
<div class="linenb">&nbsp;96</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">&nbsp;97</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">&nbsp;98</div><div class="codeline">Modern neural networks typically use gradient descent to optimize their parameters by minimizing the loss function. The gradient of the parameter $\bm{w}$, designated in literature as $\bm{\theta}$, with respect to the loss function $\mathcal{L}$ is subtracted each optimization step $t$</div><div class="clear"></div>
<div class="linenb">&nbsp;99</div><div class="codeline"><span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">100</div><div class="codeline">&nbsp;&nbsp;\bm{\theta}_{t+1} = \bm{\theta}_t - \frac{\partial \mathcal{L}}{\partial \bm{\theta}}</div><div class="clear"></div>
<div class="linenb">101</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">102</div><div class="codeline">This induces $\mathcal{L}$  needs to be differentiable with respect to $\bm{\theta}$, thus the layers and their activation functions also need to be differentiable. This simple gradient descent, designated as Stochastic Gradient Descent (SGD), can be extended with first and second order momenta like in the Adam optimizer \cite{kingma_adam_2017}. More details about the optimizers can be found in Section \ref{sec:ml:optim}.</div><div class="clear"></div>
<div class="linenb">103</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">104</div><div class="codeline"><span class="keyword1">\subsubsection</span>{Training lifecycle}</div><div class="clear"></div>
<div class="linenb">105</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">106</div><div class="codeline">The training process of neural networks can vary depending on the application and dataset, but in this thesis, we follow a standard approach. As shown in Fig. \ref{fig:ml:lifecycle}, training is organized into <span class="keyword1">\textit</span>{epochs}, each of which consists of several <span class="keyword1">\textit</span>{steps}. During each step, the neural network optimizes its parameters using a <span class="keyword1">\textit</span>{batch}, a subset of the entire training dataset.</div><div class="clear"></div>
<div class="linenb">107</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">108</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[ht]</div><div class="clear"></div>
<div class="linenb">109</div><div class="codeline">&nbsp;&nbsp;\centering</div><div class="clear"></div>
<div class="linenb">110</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\includegraphics</span>[height=6cm]{images/ml/lifecycle.jpg}</div><div class="clear"></div>
<div class="linenb">111</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\caption</span>{Illustration of the training lifecycles.}</div><div class="clear"></div>
<div class="linenb">112</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\label</span>{fig:ml:lifecycle}</div><div class="clear"></div>
<div class="linenb">113</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">114</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">115</div><div class="codeline">The ideal batch size vary depending on the problematic, as it has been shown that too big of a batch size could lead to the network being stuck in local minima, while too small batch size tend to lead to noisy response from the network. Moreover, in our case, we are limited by the memory consumption as our dataset, or even to big batches, might not fully fit in memory.</div><div class="clear"></div>
<div class="linenb">116</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">117</div><div class="codeline">At the end of each epoch, the neural network is evaluated on a validation dataset, which is not used during training. This dataset serves as a reference to assess the network's performance and avoid potential pitfalls such as overfitting. Those pitfalls will be further discussed in Section \ref{sec:ml:pitfall}. In JUNO, this is critical because the model needs to generalize well to unseen experimental data and avoid focussing on noise in the training dataset.</div><div class="clear"></div>
<div class="linenb">118</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">119</div><div class="codeline">Hyperparameters that can be optimized during the training can be optimized at each epoch, for example the learning rate, or each step, the optimizer momentum for example.</div><div class="clear"></div>
<div class="linenb">120</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">121</div><div class="codeline">There is not really a typical number of epochs or steps for the training. The number steps can be defined such as in one epoch, the NN see the entirety of the dataset but the number of steps and epochs are hyperparameters that are optimized over each subsequent training. We adjust them by looking at the loss evolution profile over time.</div><div class="clear"></div>
<div class="linenb">122</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">123</div><div class="codeline">Most training are started with a fixed number of epochs, i.e.\ from what we've seen from precedent training the network stop learning -- the loss is constant -- after $N$ epoch, so we run the training for $N+\delta$ epochs to see if the modification brings improvements to the loss profile.</div><div class="clear"></div>
<div class="linenb">124</div><div class="codeline">We can implement <span class="keyword1">\textit</span>{early stopping policies} to halt training if certain conditions are met, such as a sudden increase in loss or when the loss plateaus. However, for the JUNO experiment, where training time is not a strict limitation, early stopping is less critical, though it may still be useful to prevent overfitting in some cases</div><div class="clear"></div>
<div class="linenb">125</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">126</div><div class="codeline"><span class="keyword1">\subsubsection</span>{The optimizer}</div><div class="clear"></div>
<div class="linenb">127</div><div class="codeline"><span class="keyword1">\label</span>{sec:ml:optim}</div><div class="clear"></div>
<div class="linenb">128</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">129</div><div class="codeline">As briefly introduced at the beginning of this section, the parameters of the neural network are optimized using the gradient descent method. We compute the gradient of the mean loss over the batch with respect with the parameters, and we update them in order to minimize the loss. The  gradient is computed backward from the loss up to the first layer parameters using the chain rule, in this case with only one parameter at each step for simplicity:</div><div class="clear"></div>
<div class="linenb">130</div><div class="codeline"><span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">131</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\label</span>{eq:ml:backward}</div><div class="clear"></div>
<div class="linenb">132</div><div class="codeline">&nbsp;&nbsp;\frac{\partial \mathcal{L}}{\partial \theta_1} = \frac{\partial \theta_2}{\partial \theta_1} \frac{\partial \mathcal{L}}{\partial \theta_2} = \frac{\partial \theta_2}{\partial \theta_1} \frac{\partial \theta_3}{\partial \theta_2} \frac{\partial \mathcal{L}}{\partial \theta_3} = \frac{\partial \theta_2}{\partial \theta_1} \prod_{i=2}^{N-1} \frac{\partial \theta_{i+1}}{\partial \theta_i} \frac{\partial \mathcal{L}}{\partial \theta_N}</div><div class="clear"></div>
<div class="linenb">133</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">134</div><div class="codeline">where $\theta$ is a parameter,<span class="highlight" title="The personal pronoun 'I' should be uppercase.. Suggestions: [I] (11033) [lt:en:I_LOWERCASE]"> $i$</span> <span class="highlight" title="Did you mean 'am' or 'will be'?. Suggestions: [am, will be] (11035) [lt:en:PERS_PRONOUN_AGREEMENT]">is</span> the layer index. We see here that the gradient of the first layer is dependent of the gradient of all the following layers. Because the only value known at the start of the optimization procedure is $\mathcal{L}$ we compute $\frac{\partial \mathcal{L}}{\partial \theta_N}$ then, $\frac{\partial \theta_{N}}{\partial \theta_{N-1}}$, etc... This is called the <span class="keyword1">\textit</span>{backward propagation}.</div><div class="clear"></div>
<div class="linenb">135</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">136</div><div class="codeline">This update of the parameters is done following an optimizer policy. Those optimizers depend on hyperparameters. The ones used in this thesis are:</div><div class="clear"></div>
<div class="linenb">137</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">138</div><div class="codeline"><span class="keyword2">\begin{enumerate}</span></div><div class="clear"></div>
<div class="linenb">139</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\item</span> Stochastic Gradient Descent (SGD).</div><div class="clear"></div>
<div class="linenb">140</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;A simple but widely used optimizer that relies on one key hyperparameter, the learning rate (LR) / $\lambda$. It updates each step the parameters $\theta$ following</div><div class="clear"></div>
<div class="linenb">141</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">142</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\theta_{t+1} = \theta_t - \lambda \frac{\partial \mathcal{L}}{\partial \theta}\bigg|_{\theta_t}</div><div class="clear"></div>
<div class="linenb">143</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">144</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;where $t$ is the step index. It is a powerful optimizer but is very sensible to local minima of the loss in the parameters phase space as illustrated in Figure \ref{fig:ml:sgd}.</div><div class="clear"></div>
<div class="linenb">145</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">146</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\item</span> Adam Optimizer \cite{kingma_adam_2017}. The concept is, in short, to have and SGD but with momentum. Adam possess two momentum $m(\beta_1)$ and $v(\beta_2)$ which are respectively proportional to $\frac{\partial \mathcal{L}}{\partial \theta}$ and $(\frac{\partial \mathcal{L}}{\partial \theta})^2$. $\beta_1$ and $\beta_2$ are hyperparameters that dictate the moment update at each optimization step. The parameters are then upgraded following <span class="keyword2">\begin{align}</span></div><div class="clear"></div>
<div class="linenb">147</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;m_{t+1} &amp;= \beta_1 m_t + (1 - \beta_1) \frac{\partial \mathcal{L}}{\partial \theta} \\</div><div class="clear"></div>
<div class="linenb">148</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;v_{t+1} &amp;= \beta_2 v_t + (1 - \beta_2) \bigg(\frac{\partial \mathcal{L}}{\partial \theta}\bigg)^2 \\</div><div class="clear"></div>
<div class="linenb">149</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\theta_{t+1} &amp;= \theta_{t} - \lambda \frac{m_{t+1}}{\sqrt{v_{t+1}} + \epsilon}</div><div class="clear"></div>
<div class="linenb">150</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword2">\end{align}</span></div><div class="clear"></div>
<div class="linenb">151</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="highlight" title="This sentence does not start with an uppercase letter.. Suggestions: [Where] (11820) [lt:en:UPPERCASE_SENTENCE_START]">where</span> $\epsilon$ is a small number to prevent divergence when $v$ is close to 0. These momenta allow overcoming small local minima in the parameters phase. Imagine ball going down a slope as illustrated in \ref{fig:ml:sgd}, if you ignore the stored momentum you get SGD and get stuck as on the left plot. Now if you consider the momentum you get over the hill and end up in the global minima.</div><div class="clear"></div>
<div class="linenb">152</div><div class="codeline"><span class="keyword2">\end{enumerate}</span></div><div class="clear"></div>
<div class="linenb">153</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">154</div><div class="codeline"><span class="keyword2">\begin{figure}</span></div><div class="clear"></div>
<div class="linenb">155</div><div class="codeline">&nbsp;&nbsp;\centering</div><div class="clear"></div>
<div class="linenb">156</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\begin{subfigure}</span>[t]{0.48\linewidth}</div><div class="clear"></div>
<div class="linenb">157</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\includegraphics</span>[height=6cm]{images/ml/sgd.jpg}</div><div class="clear"></div>
<div class="linenb">158</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\caption</span>{Illustration of SGD falling into a local minima.}</div><div class="clear"></div>
<div class="linenb">159</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\label</span>{fig:ml:sgd}</div><div class="clear"></div>
<div class="linenb">160</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\end{subfigure}</span></div><div class="clear"></div>
<div class="linenb">161</div><div class="codeline">&nbsp;&nbsp;\hfill</div><div class="clear"></div>
<div class="linenb">162</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\begin{subfigure}</span>[t]{0.48\linewidth}</div><div class="clear"></div>
<div class="linenb">163</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\includegraphics</span>[height=6cm]{images/ml/Adam.jpg}</div><div class="clear"></div>
<div class="linenb">164</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\caption</span>{Illustration of the Adam momentum allowing it to overcome local minima.}</div><div class="clear"></div>
<div class="linenb">165</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\label</span>{fig:ml:adam}</div><div class="clear"></div>
<div class="linenb">166</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\end{subfigure}</span></div><div class="clear"></div>
<div class="linenb">167</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\caption</span>{}</div><div class="clear"></div>
<div class="linenb">168</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">169</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">170</div><div class="codeline"><span class="keyword1">\subsubsection</span>{Learning Rate (LR) Schedules}</div><div class="clear"></div>
<div class="linenb">171</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">172</div><div class="codeline">The learning rate plays a crucial role in determining how fast or slow the model converges. If the learning rate is too high (Fig. \ref{fig:ml:optims:mae}), the model may skip over the optimal solution, whereas a low learning rate (Fig. \ref{fig:ml:optims:mse}) can slow down the convergence process, leading to inefficient training. To address this, learning rate schedulers are employed.</div><div class="clear"></div>
<div class="linenb">173</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">174</div><div class="codeline">Using a learning rate scheduler allows the optimizer to take larger steps in the early stages of training, where rapid learning is beneficial, and progressively smaller steps as the model approaches convergence. This strategy is especially useful in JUNO, where early learning from noisy data may require coarse adjustments, but fine-tuning is needed later to accurately capture subtle event characteristics.</div><div class="clear"></div>
<div class="linenb">175</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">176</div><div class="codeline"><span class="keyword2">\begin{figure}</span></div><div class="clear"></div>
<div class="linenb">177</div><div class="codeline">&nbsp;&nbsp;\centering</div><div class="clear"></div>
<div class="linenb">178</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\begin{subfigure}</span>[t]{0.48\linewidth}</div><div class="clear"></div>
<div class="linenb">179</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\includegraphics</span>[height=6cm]{scripts/plots/MAE_illustration.png}</div><div class="clear"></div>
<div class="linenb">180</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\caption</span>{Illustration of the SGD optimizer on one parameter $\theta$ on the MAE Loss. We see here that it has trouble reaching the minima due to the gradient being constant.}</div><div class="clear"></div>
<div class="linenb">181</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\label</span>{fig:ml:optims:mae}</div><div class="clear"></div>
<div class="linenb">182</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\end{subfigure}</span></div><div class="clear"></div>
<div class="linenb">183</div><div class="codeline">&nbsp;&nbsp;\hfill</div><div class="clear"></div>
<div class="linenb">184</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\begin{subfigure}</span>[t]{0.48\linewidth}</div><div class="clear"></div>
<div class="linenb">185</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\includegraphics</span>[height=6cm]{scripts/plots/MSE_illustration.png}</div><div class="clear"></div>
<div class="linenb">186</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\caption</span>{Illustration of the SGD optimizer on one parameter $\theta$ on the MSE Loss. We see two different behavior: A smooth one (orange and red) when the LR is small enough and a more chaotic one when the LR is too high.}</div><div class="clear"></div>
<div class="linenb">187</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\label</span>{fig:ml:optims:mse}</div><div class="clear"></div>
<div class="linenb">188</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\end{subfigure}</span></div><div class="clear"></div>
<div class="linenb">189</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\caption</span>{Illustration of the SGD optimizer. In blue is the value of the loss function, orange, green and red are the path taken by the optimized parameter during the training for different LR.}</div><div class="clear"></div>
<div class="linenb">190</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\label</span>{fig:ml:optims}</div><div class="clear"></div>
<div class="linenb">191</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">192</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">193</div><div class="codeline">Another policy that is often use is the save of the best model. In some situation, the loss value after each epoch will strongly oscillate or can even worsen. This policy allow us to keep the best version of the model attained during the training phase.</div><div class="clear"></div>
<div class="linenb">194</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">195</div><div class="codeline"><span class="keyword1">\subsection</span>{Potential pitfalls}</div><div class="clear"></div>
<div class="linenb">196</div><div class="codeline"><span class="keyword1">\label</span>{sec:ml:pitfall}</div><div class="clear"></div>
<div class="linenb">197</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">198</div><div class="codeline">Apart from being stuck in local minima, there is also other behaviors and effects we want to prevent during training.</div><div class="clear"></div>
<div class="linenb">199</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">200</div><div class="codeline"><span class="keyword1">\subsubsection</span>{Overtraining}</div><div class="clear"></div>
<div class="linenb">201</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">202</div><div class="codeline">Overfitting occurs when a neural network memorizes specific details or noise from the training dataset rather than learning a general representation of the underlying data. This is common when the training dataset is small relative to the number of parameters in the network or when the dataset contains specific features that do not generalize well to unseen data. Additionally, training the network for too many epochs can exacerbate this issue. Figure \ref{fig:ml:overtraining} illustrates the impact of overfitting, where the model fits the training data too closely, compromising its ability to generalize.</div><div class="clear"></div>
<div class="linenb">203</div><div class="codeline">To detect overfitting, techniques like monitoring the validation loss, early stopping, or employing cross-validation can be employed. In JUNO's context, managing overfitting is critical due to the large volume of data generated by the photomultiplier tubes (PMTs), which may include noise or other artifacts.</div><div class="clear"></div>
<div class="linenb">204</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">205</div><div class="codeline">Overtraining can be fought in multiple ways, for example:</div><div class="clear"></div>
<div class="linenb">206</div><div class="codeline"><span class="keyword2">\begin{itemize}</span></div><div class="clear"></div>
<div class="linenb">207</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{More data}. By having more data in the training dataset, the network will not be able the specificities of every data.</div><div class="clear"></div>
<div class="linenb">208</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{Fewer parameters}. By reducing the number of parameters, we reduce the computing and learning capacities of the network. This will force it to fall back to generalist behaviors.</div><div class="clear"></div>
<div class="linenb">209</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{Dropout}. This technique implies to randomly set some neurons to 0, i.e.\ cutting the relation between two neurons in a layer. By doing this, we force the network to allocate more of its parameter to the features learning, preventing those parameters to be used for overtraining.</div><div class="clear"></div>
<div class="linenb">210</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{Early stopping}. During the training we monitor the network performance over a validation dataset. The network does not train on this dataset and thus cannot learn its specificities. If the loss on the training dataset diverge too much from the loss on the validation dataset, we can stop the training earlier to prevent it from overtraining.</div><div class="clear"></div>
<div class="linenb">211</div><div class="codeline"><span class="keyword2">\end{itemize}</span></div><div class="clear"></div>
<div class="linenb">212</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">213</div><div class="codeline"><span class="keyword2">\begin{figure}</span></div><div class="clear"></div>
<div class="linenb">214</div><div class="codeline">&nbsp;&nbsp;\centering</div><div class="clear"></div>
<div class="linenb">215</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\begin{subfigure}</span>[t]{0.48\linewidth}</div><div class="clear"></div>
<div class="linenb">216</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;\centering</div><div class="clear"></div>
<div class="linenb">217</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\includegraphics</span>[height=6cm]{images/ml/overtraining.jpg}</div><div class="clear"></div>
<div class="linenb">218</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\caption</span>{Illustration of overtraining. The task at hand is to determine depending on two input variable $x$ and $y$ if the data belong to the dataset $A$ or the dataset $B$. The expected boundary between the two dataset is represented in grey. A possible boundary learnt by overtraining is represented in brown.}</div><div class="clear"></div>
<div class="linenb">219</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\label</span>{fig:ml:overtraining}</div><div class="clear"></div>
<div class="linenb">220</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\end{subfigure}</span></div><div class="clear"></div>
<div class="linenb">221</div><div class="codeline">&nbsp;&nbsp;\hfill</div><div class="clear"></div>
<div class="linenb">222</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\begin{subfigure}</span>[t]{0.48\linewidth}</div><div class="clear"></div>
<div class="linenb">223</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;\centering</div><div class="clear"></div>
<div class="linenb">224</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\includegraphics</span>[height=6cm]{images/ml/vanishing_illus.jpg}</div><div class="clear"></div>
<div class="linenb">225</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\caption</span>{Illustration of a very simple NN.}</div><div class="clear"></div>
<div class="linenb">226</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\label</span>{fig:ml:vanishing}</div><div class="clear"></div>
<div class="linenb">227</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\end{subfigure}</span></div><div class="clear"></div>
<div class="linenb">228</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\caption</span>{}</div><div class="clear"></div>
<div class="linenb">229</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">230</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">231</div><div class="codeline"><span class="keyword1">\subsubsection</span>{Gradient vanishing}</div><div class="clear"></div>
<div class="linenb">232</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">233</div><div class="codeline">Gradient vanishing is the effect of the gradient being so small for the early layers that the parameters are barely updated after each step. This cause the network to be unable to converge to the minima.</div><div class="clear"></div>
<div class="linenb">234</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">235</div><div class="codeline">This comes from the way the gradient descent is calculated. Imagine a simple network composed of three fully connected layers: the input layer, an intermediate layer and the output layer. Let $L$ be the loss, $\theta_1$ the parameter between the input and the intermediate layer and $\theta_2$ the parameter between the intermediate and output layer. This network is schematized in Figure \ref{fig:ml:vanishing}.</div><div class="clear"></div>
<div class="linenb">236</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">237</div><div class="codeline">The gradient for $\theta_1$ will be computed using the chain rule presented in equation \ref{eq:ml:backward}. Because $\theta_1$ depends on $\theta_2$, if the gradient of $\theta_2$ is small, so will be the gradient of $\theta_1$. Now if we would have much more layer, we can see how the subsequent multiplication of small gradients would lead to very small update of the parameters thus ``<span class="keyword1">\textit</span>{vanishing gradient}''.</div><div class="clear"></div>
<div class="linenb">238</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">239</div><div class="codeline">Multiple actions can be taken to prevent this effect such as:</div><div class="clear"></div>
<div class="linenb">240</div><div class="codeline"><span class="keyword2">\begin{itemize}</span></div><div class="clear"></div>
<div class="linenb">241</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{Batch normalization}: In this case we apply a normalization layer that will normalize the data. It means that we transform the input variable $X$ into a variable $D$ which distribution follow $\langle D \rangle = 0$ and $\sigma D = 1$. This helps the parameters of the network to maintain an appropriate scale.</div><div class="clear"></div>
<div class="linenb">242</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{Residual Network (ResNet)} \cite{he_deep_2016}: Residual network is a technique for neural network in which, instead of just sequentially feeding the results of each layer to the next one, you compute a residual over the input data. This technique is illustrated in Figure \ref{fig:ml:resnet}. The reference \cite{he_deep_2016} show empirical evidence of its relevance.</div><div class="clear"></div>
<div class="linenb">243</div><div class="codeline"><span class="keyword2">\end{itemize}</span></div><div class="clear"></div>
<div class="linenb">244</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">245</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">246</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[ht]</div><div class="clear"></div>
<div class="linenb">247</div><div class="codeline">&nbsp;&nbsp;\centering</div><div class="clear"></div>
<div class="linenb">248</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\includegraphics</span>[height=6cm]{images/ml/resnet.png}</div><div class="clear"></div>
<div class="linenb">249</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\caption</span>{Illustration of the ResNet framework.}</div><div class="clear"></div>
<div class="linenb">250</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\label</span>{fig:ml:resnet}</div><div class="clear"></div>
<div class="linenb">251</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">252</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">253</div><div class="codeline"><span class="keyword1">\subsubsection</span>{Gradient explosion}</div><div class="clear"></div>
<div class="linenb">254</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">255</div><div class="codeline">Gradient explosion occurs when gradients grow exponentially during back-propagation, causing parameter values to increase dramatically. This is particularly problematic in deep networks where the product of large gradients across layers can lead to unstable updates. In practice, gradient explosion is often caused by large learning rates, poor weight initialization, or non-linearities in the network.</div><div class="clear"></div>
<div class="linenb">256</div><div class="codeline">For illustration, consider that the loss dependency in $\theta$ follow</div><div class="clear"></div>
<div class="linenb">257</div><div class="codeline"><span class="keyword2">\begin{align*}</span></div><div class="clear"></div>
<div class="linenb">258</div><div class="codeline">&nbsp;&nbsp;\mathcal{L}(\theta) &amp;= \frac{\theta^2}{2} + e^{4\theta} \\</div><div class="clear"></div>
<div class="linenb">259</div><div class="codeline">&nbsp;&nbsp;\frac{\partial \mathcal{L}}{\partial \theta} &amp;= \theta + 4e^{4\theta}</div><div class="clear"></div>
<div class="linenb">260</div><div class="codeline"><span class="keyword2">\end{align*}</span></div><div class="clear"></div>
<div class="linenb">261</div><div class="codeline">The explosion is illustrated in Figure \ref{fig:ml:explosion} where we can see that the loss degrade with each step of optimization. In this illustration it is clear that reducing the learning rate suffice, but this behavior can happen in the middle of the training where the learning rate schedule does not permit reactivity.</div><div class="clear"></div>
<div class="linenb">262</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">263</div><div class="codeline">There exist solutions to prevent these explosions:</div><div class="clear"></div>
<div class="linenb">264</div><div class="codeline"><span class="keyword2">\begin{itemize}</span></div><div class="clear"></div>
<div class="linenb">265</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{Gradient clipping}: Is this case we work on the gradient so that the norm of gradient vector does not exceed a certain threshold. In our illustration in Figure \ref{fig:ml:explosion} the gradient for $\theta &gt; 0$ could be clipped at 3 for example.</div><div class="clear"></div>
<div class="linenb">266</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\item</span> <span class="keyword1">\textbf</span>{Batch normalization}: For the same reasons as for gradient vanishing, normalizing the input data help reduce erratic behavior.</div><div class="clear"></div>
<div class="linenb">267</div><div class="codeline"><span class="keyword2">\end{itemize}</span></div><div class="clear"></div>
<div class="linenb">268</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">269</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">270</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[ht]</div><div class="clear"></div>
<div class="linenb">271</div><div class="codeline">&nbsp;&nbsp;\centering</div><div class="clear"></div>
<div class="linenb">272</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\includegraphics</span>[height=6cm]{scripts/plots/MSE_explosion_illustration.png}</div><div class="clear"></div>
<div class="linenb">273</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\caption</span>{Illustration of the gradient explosion. Here it can be solved with a lower learning rate but its not always the case.}</div><div class="clear"></div>
<div class="linenb">274</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\label</span>{fig:ml:explosion}</div><div class="clear"></div>
<div class="linenb">275</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">276</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">277</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">278</div><div class="codeline"><span class="keyword1">\section</span>{Neural networks architectures}</div><div class="clear"></div>
<div class="linenb">279</div><div class="codeline"><span class="keyword1">\label</span>{sec:ml:architecture}</div><div class="clear"></div>
<div class="linenb">280</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">281</div><div class="codeline"><span class="keyword1">\subsection</span>{Fully Connected Deep Neural Network (FCDNN)}</div><div class="clear"></div>
<div class="linenb">282</div><div class="codeline"><span class="keyword1">\label</span>{sec:ml:fcdnn}</div><div class="clear"></div>
<div class="linenb">283</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">284</div><div class="codeline">In this thesis, FCDNN serves as a baseline architecture for comparison with more specialized models like CNNs (see Section \ref{sec:ml:cnn}) and GNNs (see Section \ref{sec:ml:gnn}), which are better suited to structured or graph-based data. However, FCDNNs are still useful when modeling highly abstract relationships, such as aggregating features from the JUNO PMTs. While they are powerful, their main drawback lies in their inefficiency when dealing with high-dimensional or spatially structured data, which will be addressed with convolutional architectures.</div><div class="clear"></div>
<div class="linenb">285</div><div class="codeline">This architecture is the stack of multiple fully connected layers as presented in the Figure \ref{fig:ml:fcdnn}. Most of the time, the classic ReLU function</div><div class="clear"></div>
<div class="linenb">286</div><div class="codeline"><span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">287</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\label</span>{eq:ml:relu}</div><div class="clear"></div>
<div class="linenb">288</div><div class="codeline">&nbsp;&nbsp;\mathrm{ReLU}(x) = <span class="keyword2">\begin{cases}</span></div><div class="clear"></div>
<div class="linenb">289</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;x &amp; \mathrm{if} ~ x \geq 0 \\</div><div class="clear"></div>
<div class="linenb">290</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;0 &amp; \mathrm{otherwise}</div><div class="clear"></div>
<div class="linenb">291</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\end{cases}</span></div><div class="clear"></div>
<div class="linenb">292</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">293</div><div class="codeline">is used as activation function. PReLU and Sigmoid are also popular choices:</div><div class="clear"></div>
<div class="linenb">294</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">295</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">296</div><div class="codeline"><span class="keyword2">\begin{minipage}</span>{0.5\linewidth}</div><div class="clear"></div>
<div class="linenb">297</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">298</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\label</span>{sec:ml:sigmoid}</div><div class="clear"></div>
<div class="linenb">299</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;\mathrm{Sigmoid}(x) = \frac{1}{1+ e^{-x}}</div><div class="clear"></div>
<div class="linenb">300</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">301</div><div class="codeline"><span class="keyword2">\end{minipage}</span></div><div class="clear"></div>
<div class="linenb">302</div><div class="codeline"><span class="keyword2">\begin{minipage}</span>{0.5\linewidth}</div><div class="clear"></div>
<div class="linenb">303</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">304</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\label</span>{sec:ml:prelu}</div><div class="clear"></div>
<div class="linenb">305</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;\mathrm{PReLU}(x) = <span class="keyword2">\begin{cases}</span></div><div class="clear"></div>
<div class="linenb">306</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x &amp; \mathrm{if} ~ x \geq 0 \\</div><div class="clear"></div>
<div class="linenb">307</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\alpha x &amp; \mathrm{otherwise}</div><div class="clear"></div>
<div class="linenb">308</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword2">\end{cases}</span></div><div class="clear"></div>
<div class="linenb">309</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">310</div><div class="codeline"><span class="keyword2">\end{minipage}</span></div><div class="clear"></div>
<div class="linenb">311</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">312</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">313</div><div class="codeline">The reasoning behind ReLU and PReLU is that with enough of them, you can mimic any continuous function as illustrated in Figure \ref{fig:ml:relu-mimic}. Sigmoid is more used in case of classification, its behavior going hand in hand with the Cross Entropy loss function used in classification problems.</div><div class="clear"></div>
<div class="linenb">314</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">315</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[ht]</div><div class="clear"></div>
<div class="linenb">316</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\begin{subfigure}</span>[t]{0.48\textwidth}</div><div class="clear"></div>
<div class="linenb">317</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;\centering</div><div class="clear"></div>
<div class="linenb">318</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\includegraphics</span>[height=6cm]{images/ml/fcdnn_scheme.jpg}</div><div class="clear"></div>
<div class="linenb">319</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\caption</span>{Schema of a FCDNN.}</div><div class="clear"></div>
<div class="linenb">320</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\label</span>{fig:ml:fcdnn}</div><div class="clear"></div>
<div class="linenb">321</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\end{subfigure}</span></div><div class="clear"></div>
<div class="linenb">322</div><div class="codeline">&nbsp;&nbsp;\hfill</div><div class="clear"></div>
<div class="linenb">323</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\begin{subfigure}</span>[t]{0.48\textwidth}</div><div class="clear"></div>
<div class="linenb">324</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;\centering</div><div class="clear"></div>
<div class="linenb">325</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\includegraphics</span>[height=6cm]{images/ml/relu_approx.png}</div><div class="clear"></div>
<div class="linenb">326</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\caption</span>{Illustration of a composition of ReLU ``approximating'' a function. (1) No ReLU is taking effect (2) One ReLU is activating (3) Another ReLU is activating.}</div><div class="clear"></div>
<div class="linenb">327</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\label</span>{fig:ml:relu-mimic}</div><div class="clear"></div>
<div class="linenb">328</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\end{subfigure}</span></div><div class="clear"></div>
<div class="linenb">329</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\caption</span>{}</div><div class="clear"></div>
<div class="linenb">330</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">331</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">332</div><div class="codeline">Due to its simplicity, FCDNN are also used as basic pieces for more complex architectures such as the CNN and GNN that will be presented in the next sections.</div><div class="clear"></div>
<div class="linenb">333</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">334</div><div class="codeline"><span class="keyword1">\subsection</span>{Convolutional Neural Network (CNN)}</div><div class="clear"></div>
<div class="linenb">335</div><div class="codeline"><span class="keyword1">\label</span>{sec:ml:cnn}</div><div class="clear"></div>
<div class="linenb">336</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">337</div><div class="codeline">It's not trivial to describe in text the principles of Convolutional Neural Network (CNN) and how they work. We try a general description below followed by a step by step description of a concrete example.</div><div class="clear"></div>
<div class="linenb">338</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">339</div><div class="codeline">Convolutional Neural Networks are a family of neural networks that use discrete convolution filters, as illustrated in an example in Figure \ref{fig:ml:conv_filter}, to process the input data, often images. They are commonly used in image recognition \cite{russakovsky_imagenet_2015} for classification or regression problematics. Concretely, you multiply element-wise a portion of the input data, in the case of an image, a small part of the image, with a kernel of same dimension. In Figure \ref{fig:ml:conv_filter}, we multiply the $3\times3$ pixels sub-image with the $3\times3$ kernel.</div><div class="clear"></div>
<div class="linenb">340</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">341</div><div class="codeline">Their filters scan the input data, highlighting patterns of interest, this scanning procedure making them translation-invariant. In the concrete case of Figure \ref{fig:ml:conv_filter}, for each pixel of the input image, we group it with the 8 neighbors pixel and produce a new pixel that correspond to the output image. For the pixel on the edges that do not have neighbors, we either create ``imaginary'' pixel with the value 0, or we just ignore them. If we ignore them, the output image will possess fewer pixels than the input image. We see that the operation do not care where is the pattern of interest in the images, the filter output will be <span class="keyword1">\textit</span>{invariant} whatever <span class="keyword1">\textit</span>{translation} is applied to the image.</div><div class="clear"></div>
<div class="linenb">342</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">343</div><div class="codeline">This invariance mean that they are capable of detecting oriented features independently of their location on the image.</div><div class="clear"></div>
<div class="linenb">344</div><div class="codeline">These filters scan the input, highlighting important features like edges or textures, which in JUNO's case could represent spatial correlations in the timing and charge data across the detector. As the network goes deeper, it can capture more complex and abstract features, making it ideal for detecting nuanced particle interactions.</div><div class="clear"></div>
<div class="linenb">345</div><div class="codeline">Again taking \ref{fig:ml:conv_filter} as an example, with only the 9 parameters composing the kernel, we can highlight the contour of the duck by looking at the ``yellowness'' of the pixels.</div><div class="clear"></div>
<div class="linenb">346</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">347</div><div class="codeline">The learning parameters of CNNs are the kernels components, the network thus learn the optimal filters to extract the desired features.</div><div class="clear"></div>
<div class="linenb">348</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">349</div><div class="codeline">The convolution layers are commonly chained \cite{simonyan_very_2015}, reducing the input dimension while increasing the number of filters. The idea behind is that the first layers will process local information and the latest layers will process more global information, as the latest convolution filters will process the results of the preceding ones, that themselves have processed local information. To try to preserve the amount of information, we tend to grow the numbers of filters for each reduction of the input data.</div><div class="clear"></div>
<div class="linenb">350</div><div class="codeline">The results of the convolution filters is commonly then flattened and feed to a smaller FCDNN which will process the filters results to yield the desired output.</div><div class="clear"></div>
<div class="linenb">351</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">352</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[ht]</div><div class="clear"></div>
<div class="linenb">353</div><div class="codeline">&nbsp;&nbsp;\centering</div><div class="clear"></div>
<div class="linenb">354</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\includegraphics</span>[height=6cm]{images/ml/convolution_exammple.jpg}</div><div class="clear"></div>
<div class="linenb">355</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\caption</span>{Illustration of the effect of a convolution filter. Here we apply a filter with the aim do detect left edges. We see in the resulting image that the left edges of the duck are bright yellow where the right edges are dark blue indicating the contour of the object. The convolution was calculated using \cite{allen_generic-github-userimage-convolution-playground_2024}.}</div><div class="clear"></div>
<div class="linenb">356</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\label</span>{fig:ml:conv_filter}</div><div class="clear"></div>
<div class="linenb">357</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">358</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">359</div><div class="codeline">As an example, let's take the Pytorch \cite{ansel_pytorch_2024} example for the MNIST \cite{lecun_gradient-based_1998}, a dataset of black and white images of handwritten digits. Those images are $28 \times 28$ pixels with only one channel corresponding to the gray level of the pixel. Example of images from this dataset are presented in Figure \ref{fig:ml:mnist}</div><div class="clear"></div>
<div class="linenb">360</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">361</div><div class="codeline">A schema of the CNN used in the Pytorch example is presented in Figure \ref{fig:ml:cnn_mnist}. Using this schema as a reference, the trained network is made of:</div><div class="clear"></div>
<div class="linenb">362</div><div class="codeline"><span class="keyword2">\begin{enumerate}</span></div><div class="clear"></div>
<div class="linenb">363</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\item</span> A convolutional layer of $(3 \times 3)$ filters yielding 32 channels. A bias parameter is applied to each channel for a total of $(32 \cdot (3\times3) + 32) = 320$ parameters. The resulting image is $(26\times26 \times 32)$ (26 per 26 pixels with 32 channels). The ReLU activation function is applied to each pixel.</div><div class="clear"></div>
<div class="linenb">364</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\item</span> A second convolutional layer of $(3 \times 3)$ filters yielding 64 channels. This channel also posses a bias parameter for a total of $(64 \cdot (3\times3) + 64) = 640$ parameters. Resulting image is $(24\times24\times64)$. This channel also apply a ReLU activation function.</div><div class="clear"></div>
<div class="linenb">365</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\item</span> Then comes <span class="highlight" title="Use 'an' instead of 'a' if the following word starts with a vowel sound, e.g. 'an article', 'an hour'.. Suggestions: [an] (23136) [lt:en:EN_A_VS_AN]">a</span> $(2\times2)$ max pool layer with a stride of 1 meaning that for each channel the max value of pixels in <span class="highlight" title="Use 'an' instead of 'a' if the following word starts with a vowel sound, e.g. 'an article', 'an hour'.. Suggestions: [an] (23231) [lt:en:EN_A_VS_AN]">a</span> $(2\times2)$ block is condensed in a single resulting pixel. The resulting image is $(12 \times 12 \times 64)$.</div><div class="clear"></div>
<div class="linenb">366</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\item</span> This image goes through a dropout layer which will set the pixel to 0 with a probability of 0.25. This layer helps prevent overtraining the neural network (see Section \ref{sec:ml:pitfall} for more details).</div><div class="clear"></div>
<div class="linenb">367</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\item</span> The data is the flattened i.e.\ condensed into a vector of $(12 \times 12 \times 64) = 9216$ values.</div><div class="clear"></div>
<div class="linenb">368</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\item</span> Then comes a fully connected linear layer (Eq.\ \ref{eq:ml:fully-connected}) with a ReLU activation that output 128 features. It requires $(9216 \cdot 128)+ 128 = 1'179'776$ parameters.</div><div class="clear"></div>
<div class="linenb">369</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\item</span> This 128 item vector goes through another dropout layer with a probability of $0.5$</div><div class="clear"></div>
<div class="linenb">370</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\item</span> The vector is then transformed through a linear layer with ReLU activation. It output 10 values, one for each digit class ($0, 1, 2, \dots, 9$). It requires $(128 \cdot 10) + 128 = 1408$ parameters.</div><div class="clear"></div>
<div class="linenb">371</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\item</span> Finally, the 10 values are normalized using a log <span class="highlight-spelling" title="Possible spelling mistake found.. Suggestions: [Soft max] (23990) [lt:en:MORFOLOGIK_RULE_EN_US]">Softmax</span> function $\mathrm{LogSoftmax}(x_i) = \log \bigg(\frac{\exp(x_i)}{\sum_j \exp(x_j)}\bigg)$. Each of those values are the probability of the input image to be a certain digit.</div><div class="clear"></div>
<div class="linenb">372</div><div class="codeline"><span class="keyword2">\end{enumerate}</span></div><div class="clear"></div>
<div class="linenb">373</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">374</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[ht]</div><div class="clear"></div>
<div class="linenb">375</div><div class="codeline">&nbsp;&nbsp;\centering</div><div class="clear"></div>
<div class="linenb">376</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\begin{subfigure}</span>[t]{0.48\linewidth}</div><div class="clear"></div>
<div class="linenb">377</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\includegraphics</span>[width=\linewidth]{images/ml/MnistExamples.png}</div><div class="clear"></div>
<div class="linenb">378</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\caption</span>{Example of images in the MNIST dataset.}</div><div class="clear"></div>
<div class="linenb">379</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\label</span>{fig:ml:mnist}</div><div class="clear"></div>
<div class="linenb">380</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\end{subfigure}</span></div><div class="clear"></div>
<div class="linenb">381</div><div class="codeline">&nbsp;&nbsp;\hfill</div><div class="clear"></div>
<div class="linenb">382</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\begin{subfigure}</span>[t]{0.48\linewidth}</div><div class="clear"></div>
<div class="linenb">383</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\includegraphics</span>[width=\linewidth]{images/ml/mnist_cnn.jpg}</div><div class="clear"></div>
<div class="linenb">384</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\caption</span>{Schema of the CNN used in Pytorch example to process the MNIST dataset.}</div><div class="clear"></div>
<div class="linenb">385</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\label</span>{fig:ml:cnn_mnist}</div><div class="clear"></div>
<div class="linenb">386</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\end{subfigure}</span></div><div class="clear"></div>
<div class="linenb">387</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\caption</span>{}</div><div class="clear"></div>
<div class="linenb">388</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">389</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">390</div><div class="codeline">The final network requires 1'182'144 parameters or, if we consider each parameter to be a double precision floating point, 9.45 MB of data. To gives an order of magnitude, such neural network is considered ``simple'', train in a matter of minutes on T4 GPU \cite{noauthor_nvidia_nodate} (14 epochs) and reach an accuracy in its prediction of 99\%.</div><div class="clear"></div>
<div class="linenb">391</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">392</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">393</div><div class="codeline"><span class="keyword1">\subsection</span>{Graph Neural Network (GNN)}</div><div class="clear"></div>
<div class="linenb">394</div><div class="codeline"><span class="keyword1">\label</span>{sec:ml:gnn}</div><div class="clear"></div>
<div class="linenb">395</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">396</div><div class="codeline">In GNNs, data is represented as nodes and edges in a graph, which allows us to model the JUNO detector as a network of PMTs, where each PMT is a node and the edges represent relationships such as spatial distance or timing correlations between PMTs. This flexibility enables GNNs to capture complex interactions across the detector geometry that would be difficult to represent with a CNN, as the CNN neighboring scheme is stuck to the pixels indexing -- the position in the matrix representing the image.</div><div class="clear"></div>
<div class="linenb">397</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">398</div><div class="codeline">Furthermore, GNNs excel at processing non-Euclidean data, making them a natural fit for the irregular layout of the PMTs in JUNO.</div><div class="clear"></div>
<div class="linenb">399</div><div class="codeline">In this thesis, GNNs are applied to model the spatial and temporal relationships between PMTs, enabling more precise event classification and reconstruction. By leveraging the message-passing framework, the GNN can aggregate information from neighboring PMTs, allowing it to detect subtle patterns in the detector's data.</div><div class="clear"></div>
<div class="linenb">400</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">401</div><div class="codeline">To get deeper in details, we have seen in the previous section, the CNNs are powerful for image processing, and more generally any data that can be expressed as a regular, discrete space and from which the information reside in the dispersion in this space. For an image, the edges of an object and how they assemble. A red square, straight edges with a sharp angle between them, is much less representative of a duck than a yellow sphere, round edges without sharp angles.</div><div class="clear"></div>
<div class="linenb">402</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">403</div><div class="codeline">This ``image'' projection is not fitted for every problematic. The signals produced by a detector does not always have the properties of images. In the case of JUNO for example, we can create an image of two channels, one for the charge $Q$ and one for the timing $t$, but this image should be spherical. Furthermore, JUNO is by nature inhomogeneous, using two different systems: The LPMT and the SPMT. Those two systems have different regime, and thus should be processed differently. We could imagine images with four channels, two for the LPMT and two for the SPMT, or even a branched CNN with one convolution branch for the LPMT and another one for the SPMT. Anyway, the CNN will need to combine the two systems.</div><div class="clear"></div>
<div class="linenb">404</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">405</div><div class="codeline">To get around the restrictions of data representation imposed by CNNs, we can use the more flexible <span class="keyword1">\textit</span>{graph} representation.</div><div class="clear"></div>
<div class="linenb">406</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[ht]</div><div class="clear"></div>
<div class="linenb">407</div><div class="codeline">&nbsp;&nbsp;\centering</div><div class="clear"></div>
<div class="linenb">408</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\includegraphics</span>[height=6cm]{images/ml/graph_illustration.png}</div><div class="clear"></div>
<div class="linenb">409</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\caption</span>{Illustration of a graph and its tensor representation.}</div><div class="clear"></div>
<div class="linenb">410</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\label</span>{fig:ml:gnn:graph}</div><div class="clear"></div>
<div class="linenb">411</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">412</div><div class="codeline">A graph $G(\mathcal{N},\mathcal{E})$ is composed of vertex or node $n \in \mathcal{N}$ and edges $e \in \mathcal{E}$. The edges are associated to two nodes $(u, v) \in \mathcal{N}^2$, ``connecting'' them. The node and the edges can hold features, commonly represented as vector $n \in \mathbb{R}^{k_{n}}$, $e \in \mathbb{R}^{k_{e}}$ with $k_n$ and $k_e$ the number of features on the nodes and edges respectively. We can thus define a graph using two tensors $A^{ij}_{\epsilon}$ the adjacency tensor that hold the features $\epsilon \in [0, k_e]$ of the edge connecting the node $i$ and $j$ and the tensor $N^{i}_{\nu}$ that hold the features $\nu \in [0, k_n]$ of a node $i$.</div><div class="clear"></div>
<div class="linenb">413</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">414</div><div class="codeline">More figuratively, using the example in Figure \ref{fig:ml:gnn:graph}, we have a graph of 5 nodes with a color as feature. The edges have no features, we thus encode their existences as 0 or 1. In a realistic example as JUNO we could represent each PMTs as nodes and the edges between them as their relation such as distance, timing difference, etc... There no strict rules about what is a node or how they should be linked together. This abstraction allow us to represent virtually any type of detector of any geometry.</div><div class="clear"></div>
<div class="linenb">415</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">416</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[ht]</div><div class="clear"></div>
<div class="linenb">417</div><div class="codeline">&nbsp;&nbsp;\centering</div><div class="clear"></div>
<div class="linenb">418</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\includegraphics</span>[height=6cm]{images/ml/message_passing.png}</div><div class="clear"></div>
<div class="linenb">419</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\caption</span>{Illustration of the message passing algorithm. The detailed explanation can be found in Section \ref{sec:ml:gnn}.}</div><div class="clear"></div>
<div class="linenb">420</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\label</span>{fig:ml:gnn:message_passing}</div><div class="clear"></div>
<div class="linenb">421</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">422</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">423</div><div class="codeline">To process such object we need specific machine learning algorithms we call Graph neural network.</div><div class="clear"></div>
<div class="linenb">424</div><div class="codeline">To efficiently manipulate graph we need to structurally encode their property in the neural network computing architecture: each node is equivalent (as opposite to ordered data in a vector), each node has a set of neighbors, $\ldots$ One of this method is the message passing algorithm presented historically in ``Neural Message Passing for Quantum Chemistry'' \cite{gilmer_neural_2017}. In this algorithm, with each layer of message passing a new set of features is computed for each node following</div><div class="clear"></div>
<div class="linenb">425</div><div class="codeline"><span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">426</div><div class="codeline">&nbsp;&nbsp;n_i^{k+1} = \phi_u (n_i^k, \Box_j \phi_m(n_i^k, n_j^k, e^k_{ij})); ~ n_j \in \mathcal{N}'_i</div><div class="clear"></div>
<div class="linenb">427</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">428</div><div class="codeline">where $\phi_u$ is a differentiable <span class="keyword1">\textit</span>{update} function, $\Box_j$ is a differentiable <span class="keyword1">\textit</span>{aggregation} function and $\phi_m$ is a differentiable <span class="keyword1">\textit</span>{message} function. $\mathcal{N}'_i = \{n_j \in \mathcal{N} | (n_i, n_j) \in \mathcal{E}\}$ is the set of neighbors of $n_i$, i.e.\ the nodes $n_j$ from which it exists an edge $e_{i,j} \rightarrow (n_i, n_j)$. $k$ is the layer on which the message passing algorithm is applied. The update function need also a few other properties if we want to keep the graph property, most notably the permutation invariance of its parameters (example: mean, std, sum, $\ldots$). The different message, update and aggregation functions can really be any kind of function if they follow the constraint presented before, even small Neural Network.</div><div class="clear"></div>
<div class="linenb">429</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">430</div><div class="codeline">The edges features can also be updated, either by directly taking the results of $\phi_m$ or by using another message function $\phi_e$.</div><div class="clear"></div>
<div class="linenb">431</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">432</div><div class="codeline">To explain this process, let's take the situation presented in Figure \ref{fig:ml:gnn:message_passing}. We start with an input graph on left, in this case the message passing algorithm is mixing the color on each node and produce nodes of mixed color. For simplicity, the $\phi_m$ and $\phi_u$ function are the identity, they take a color and output the same color.</div><div class="clear"></div>
<div class="linenb">433</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">434</div><div class="codeline">Let's look at what's happening in the node 4. It has 3 neighbors and is a neighbor of itself. The four resulting $\phi_m$ extract the color of each node and then feed them to the $\Box$ function. The $\Box$ function just equally distribute the color in the node. Finally, the $\phi_u$ function just update the node with the output of $\Box$.</div><div class="clear"></div>
<div class="linenb">435</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">436</div><div class="codeline">Interestingly we see that the new node 4 does not have any yellow, the color of node 1. But if we were to run the message passing algorithm again, it would get some as node 2 is now partially yellow. If color here represent information, we see that multiple step are needed so that each node is ``aware'' of the information the other nodes possess.</div><div class="clear"></div>
<div class="linenb">437</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">438</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">439</div><div class="codeline">Message passing is a very generic way of describing the process of GNN, and it can be specialized for convolutional filtering \cite{defferrard_convolutional_2017}, diffusion \cite{li_diffusion_2018} and many other specific operation. GNN are used in a wide variety of application such as regression problematics, node classification, edge classification, node and edge prediction,<span class="highlight-sh" title="There should not be a space before the period at the end of a sentence. [sh:d:003]"> ..</span>.</div><div class="clear"></div>
<div class="linenb">440</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">441</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">442</div><div class="codeline">It is a very versatile but complex tool.</div><div class="clear"></div>
<div class="linenb">443</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">444</div><div class="codeline"><span class="keyword1">\subsection</span>{Adversarial Neural Network (ANN)}</div><div class="clear"></div>
<div class="linenb">445</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">446</div><div class="codeline">The adversarial machine learning, Adversarial Neural Networks (ANN) in the case of neural network, is a family of unsupervised machine learning algorithms where the learning algorithm (generator) is competing against another algorithm (discriminator). Taking the example of Generative Adversarial Networks, concept initially developed by Goodfellow et al.\ \cite{goodfellow_generative_2014}, the discriminator goal is to discriminate between data coming from a reference dataset and data produced by the generator.</div><div class="clear"></div>
<div class="linenb">447</div><div class="codeline">The generator goal, on the other hand, is to produce data that the discriminator would not be able to differentiate from data from the reference dataset. The expression of duality between the two models is represented in the loss where, at least a part of it, is driven by the results of the discriminator.</div><div class="clear"></div>
<div class="linenb">448</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">449</div><div class="codeline"><span class="keyword1">\section</span>{State of the art of the Offline IBD reconstruction in JUNO}</div><div class="clear"></div>
<div class="linenb">450</div><div class="codeline"><span class="keyword1">\label</span>{sec:juno:reco}</div><div class="clear"></div>
<div class="linenb">451</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">452</div><div class="codeline">The main reconstruction method currently run in JUNO is OMILREC, a data-driven method based on a likelihood maximization \cite{wu_new_2019, huang_improving_2021} using only the LPMTs. The first step is to reconstruct the interaction vertex from which the energy reconstruction is dependent. It is also necessary for event pairing and classification.</div><div class="clear"></div>
<div class="linenb">453</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">454</div><div class="codeline"><span class="keyword1">\subsection</span>{Interaction vertex reconstruction}</div><div class="clear"></div>
<div class="linenb">455</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">456</div><div class="codeline">To start the likelihood maximization, a rough estimation of the vertex and of the event timing is needed. We start by estimating the vertex position using a charge based algorithm.</div><div class="clear"></div>
<div class="linenb">457</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">458</div><div class="codeline"><span class="keyword1">\subsubsection</span>{Charge based algorithm}</div><div class="clear"></div>
<div class="linenb">459</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">460</div><div class="codeline">The charge-based algorithm is basically base on the charge-weighted average of the PMT position.</div><div class="clear"></div>
<div class="linenb">461</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">462</div><div class="codeline"><span class="keyword2">\begin{align}</span></div><div class="clear"></div>
<div class="linenb">463</div><div class="codeline">&nbsp;&nbsp;\vec{r}_{cb} = a\cdot\frac{\sum_i q_i \cdot \vec{r}_i}{\sum_i q_i}</div><div class="clear"></div>
<div class="linenb">464</div><div class="codeline"><span class="keyword2">\end{align}</span></div><div class="clear"></div>
<div class="linenb">465</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">466</div><div class="codeline">Where $q_i$ is the reconstructed charge of the pulse of the $i$-th PMT and $\vec{r}_i$ is its position, $\vec{r}_0$ is the reconstructed interaction position and<span class="highlight" title="Use 'an' instead of 'a' if the following word starts with a vowel sound, e.g. 'an article', 'an hour'.. Suggestions: [an] (32039) [lt:en:EN_A_VS_AN]"> $a$</span> is a scale factor introduced because a weighted average over a 3D sphere is inherently biased. Using calibration we can estimate $a \approx 1.3$ \cite{li_event_2021}. The results in Figure \ref{fig:juno:rec:cbary} shows that the reconstruction is biased from around 15 m and further. This is due to the phenomena called ``total reflection area'' or TR Area.</div><div class="clear"></div>
<div class="linenb">467</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">468</div><div class="codeline">As depicted in the Figure \ref{fig:juno:rec:refl} the optical photons, given that they have a sufficiently large incidence angle, can be deviated of their trajectories when passing through the interfaces LS-acrylic and water-acrylic due to the optical index difference. This cause photons to be lost or to be detected by PMT further than anticipated if we consider their rectilinear trajectories. This cause the charge barycenter to be located closer to the center than the event really is.</div><div class="clear"></div>
<div class="linenb">469</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">470</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[ht]</div><div class="clear"></div>
<div class="linenb">471</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\begin{subfigure}</span>[t]{0.48\textwidth}</div><div class="clear"></div>
<div class="linenb">472</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;\centering</div><div class="clear"></div>
<div class="linenb">473</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\includegraphics</span>[height=6cm]{images/juno/reco/Reflexion_scenarii.jpg}</div><div class="clear"></div>
<div class="linenb">474</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\caption</span>{Illustration of the different optical photons reflection scenarios. <span class="keyword1">\textbf</span>{1} is the reflection of the photon at the interface LS-acrylic or acrylic-water. <span class="keyword1">\textbf</span>{2} is the transmission of the photons through the interfaces. <span class="keyword1">\textbf</span>{3} is the conduction of the photon in the acrylic.}</div><div class="clear"></div>
<div class="linenb">475</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\label</span>{fig:juno:rec:refl}</div><div class="clear"></div>
<div class="linenb">476</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\end{subfigure}</span></div><div class="clear"></div>
<div class="linenb">477</div><div class="codeline">&nbsp;&nbsp;\hfill</div><div class="clear"></div>
<div class="linenb">478</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\begin{subfigure}</span>[t]{0.48\textwidth}</div><div class="clear"></div>
<div class="linenb">479</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;\centering</div><div class="clear"></div>
<div class="linenb">480</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\includegraphics</span>[height=6cm]{images/juno/reco/charge_barycenter.png}</div><div class="clear"></div>
<div class="linenb">481</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\caption</span>{Heatmap of $R_{rec}$ and $R_{rec} - R_{true}$ as a function of $R_{true}$ for 4MeV prompt signals uniformly distributed in the detector calculated by the charge based algorithm.}</div><div class="clear"></div>
<div class="linenb">482</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\label</span>{fig:juno:rec:cbary}</div><div class="clear"></div>
<div class="linenb">483</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\end{subfigure}</span></div><div class="clear"></div>
<div class="linenb">484</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\caption</span>{}</div><div class="clear"></div>
<div class="linenb">485</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">486</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">487</div><div class="codeline">It is to be noted that charge based algorithm, in addition to be biased near the edge of the detector, does not provide any information about the timing of the event. Therefore, a time based algorithm needs to be introduced to provide initial values.</div><div class="clear"></div>
<div class="linenb">488</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">489</div><div class="codeline"><span class="keyword1">\subsubsection</span>{Time based algorithm}</div><div class="clear"></div>
<div class="linenb">490</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">491</div><div class="codeline">The time based algorithm use the distribution of the time of flight corrections $\Delta t$ (Eq.\ \ref{eq:juno:rec:tof_corr}) of an event to reconstruct its vertex and $t_0$. It follows the following iterations:</div><div class="clear"></div>
<div class="linenb">492</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">493</div><div class="codeline"><span class="keyword2">\begin{enumerate}</span></div><div class="clear"></div>
<div class="linenb">494</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\item</span> Use the charge based algorithm to get an initial vertex to start the iteration.</div><div class="clear"></div>
<div class="linenb">495</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">496</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\item</span> <span class="keyword1">\label</span>{alg:rec:tba} Calculate the time of flight correction for the $i$-th PMT using <span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">497</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\label</span>{eq:juno:rec:tof_corr}</div><div class="clear"></div>
<div class="linenb">498</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\Delta t_i (j) = t_i - \mathrm{tof}_i (j)</div><div class="clear"></div>
<div class="linenb">499</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">500</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="highlight" title="This sentence does not start with an uppercase letter.. Suggestions: [Where] (33353) [lt:en:UPPERCASE_SENTENCE_START]">where</span> $j$ is the iteration step, $t_i$ is the timing of the $i$-th PMT, and $\mathrm{tof}_i$ is the time-of-flight of the photon considering a rectilinear trajectory and an effective velocity in the LS and water (see \cite{li_event_2021} for detailed description of this effective velocity). Plot the $\Delta t$ distribution and label the peak position as $\Delta t^{\mathrm{peak}}$ (see fig \ref{fig:juno:rec:delta_t_distrib}).</div><div class="clear"></div>
<div class="linenb">501</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">502</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\item</span> Calculate a correction vector $\vec{\delta} [\vec{r}(j)]$ as <span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">503</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\vec{\delta} [\vec{r}(j)] = \frac{\sum_i \bigg(\frac{\Delta t(j) - \Delta t^{\mathrm{peak}}(j)}{\mathrm{tof}_i(j)} \bigg) \cdot (\vec{r}_0(j) - \vec{r}_i)}{N^{\mathrm{peak}}(j)}</div><div class="clear"></div>
<div class="linenb">504</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">505</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="highlight" title="This sentence does not start with an uppercase letter.. Suggestions: [Where] (33680) [lt:en:UPPERCASE_SENTENCE_START]">where</span> $\vec{r}_0$ is the vertex position at the beginning of this iteration, $\vec{r}_i$ is the position of the $i$-th PMT. To minimize the effect of scattering, dark noise and reflection, only the pulse happening in a time window (-10 ns, +5 ns) around $\Delta t^{\mathrm{peak}}$ are considered. $N^{\mathrm{peak}}$ is the number of PE collected in this time-window.</div><div class="clear"></div>
<div class="linenb">506</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">507</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\item</span> If $\vec{\delta} [\vec{r}(j)] &lt; 1 \mathrm{mm}$ or $j \geq 100$, stop the iteration. Otherwise, $\vec{r}_0 (j + 1) = \vec{r}_0 (j) + \vec{\delta} [\vec{r}(j)]$ and go to step \ref{alg:rec:tba}.</div><div class="clear"></div>
<div class="linenb">508</div><div class="codeline"><span class="keyword2">\end{enumerate}</span></div><div class="clear"></div>
<div class="linenb">509</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">510</div><div class="codeline"><span class="keyword2">\begin{figure}</span></div><div class="clear"></div>
<div class="linenb">511</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\begin{subfigure}</span>[t]{0.48\textwidth}</div><div class="clear"></div>
<div class="linenb">512</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;\centering</div><div class="clear"></div>
<div class="linenb">513</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\includegraphics</span>[width=\textwidth]{images/juno/reco/delta_t_peak_distrib.png}</div><div class="clear"></div>
<div class="linenb">514</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\caption</span>{$\Delta t$ distribution at different iterations step $j$.}</div><div class="clear"></div>
<div class="linenb">515</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\label</span>{fig:juno:rec:delta_t_distrib}</div><div class="clear"></div>
<div class="linenb">516</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\end{subfigure}</span></div><div class="clear"></div>
<div class="linenb">517</div><div class="codeline">&nbsp;&nbsp;\hfill</div><div class="clear"></div>
<div class="linenb">518</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\begin{subfigure}</span>[t]{0.48\textwidth}</div><div class="clear"></div>
<div class="linenb">519</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;\centering</div><div class="clear"></div>
<div class="linenb">520</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\includegraphics</span>[width=\textwidth]{images/juno/reco/time_based_algorithm.png}</div><div class="clear"></div>
<div class="linenb">521</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\caption</span>{Heatmap of $R_{rec}$ and $R_{rec} - R_{true}$ as a function of $R_{true}$ for 4MeV prompt signals uniformly distributed in the detector calculated by the time based algorithm.}</div><div class="clear"></div>
<div class="linenb">522</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\label</span>{fig:juno:rec:time_based_results}</div><div class="clear"></div>
<div class="linenb">523</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\end{subfigure}</span></div><div class="clear"></div>
<div class="linenb">524</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\caption</span>{}</div><div class="clear"></div>
<div class="linenb">525</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">526</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">527</div><div class="codeline">However, because the earliest arrival time is used, $t_i$ is related to the number photoelectrons $N_i^{\mathrm{pe}}$ detected by the PMT \cite{ranucci_analytical_1995, galbiati_time_2006, moszynski_status_1979}. To reduce bias in the vertex reconstruction, the following equation is used to correct $t_i$ into $t'_i$:</div><div class="clear"></div>
<div class="linenb">528</div><div class="codeline"><span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">529</div><div class="codeline">&nbsp;&nbsp;t'_{i} = t_i - p_0 / \sqrt{N_i^{\mathrm{pe}}} - p_1 - p_2 / N_i^{\mathrm{pe}}</div><div class="clear"></div>
<div class="linenb">530</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">531</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">532</div><div class="codeline">The parameters $(p_0, p_1, p_2)$ were optimized to (9.42, 0.74, -4.60) for Hamamatsu PMTs and (41.31, -12.04, -20.02) for NNVT PMTs \cite{li_event_2021}. The results presented in Figure \ref{fig:juno:rec:time_based_results} shows that the time based algorithm provide a more accurate vertex and is unbiased even in the TR area. This results $(\vec{r}_0, t_0)$ is used as initial value for the likelihood algorithm.</div><div class="clear"></div>
<div class="linenb">533</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">534</div><div class="codeline"><span class="keyword1">\subsubsection</span>{Time likelihood algorithm}</div><div class="clear"></div>
<div class="linenb">535</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">536</div><div class="codeline">The time likelihood algorithm uses the residual time expressed as follows</div><div class="clear"></div>
<div class="linenb">537</div><div class="codeline"><span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">538</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\label</span>{eq:juno:rec:t_res}</div><div class="clear"></div>
<div class="linenb">539</div><div class="codeline">&nbsp;&nbsp;t_{\mathrm{res}}^i(\vec{r}_0, t_0) = t_i - \mathrm{tof}_i - t_0</div><div class="clear"></div>
<div class="linenb">540</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">541</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">542</div><div class="codeline">In a first order approximation, the scintillator time response Probability Density Function (PDF) can be described as the emission time profile of the scintillation photons, the Time Transit Spread (TTS) and the dark noise of the PMTs. The emission time profile $f(t_{\mathrm{res}})$ is described like</div><div class="clear"></div>
<div class="linenb">543</div><div class="codeline"><span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">544</div><div class="codeline">&nbsp;&nbsp;f(t_{\mathrm{res}}) = \sum_k \frac{\rho_k}{\tau_k} e^{\frac{-t_{\mathrm{res}}}{\tau_k}}, ~ \sum_k \rho_k = 1</div><div class="clear"></div>
<div class="linenb">545</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">546</div><div class="codeline">as the sum of the $k$ component that emit light in the LS each one characterized by its decay time $\tau_k$ and intensity fraction $\rho_k$. The TTS component is expressed as a Gaussian convolution</div><div class="clear"></div>
<div class="linenb">547</div><div class="codeline"><span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">548</div><div class="codeline">&nbsp;&nbsp;g(t_{\mathrm{res}}) = \frac{1}{\sqrt{2\pi}\sigma}e^{\frac{-(t_{\mathrm{res}} - \nu)^2}{2\sigma^2}} \cdot f(t_{\mathrm{res}})</div><div class="clear"></div>
<div class="linenb">549</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">550</div><div class="codeline">where $\sigma$ is the TTS of PMTs and $\nu$ is the average transit time. The dark noise is not correlated with any physical events and considered as constant rate over the time window considered $T$. By normalizing the dark noise probability $\epsilon(t_{\mathrm{res}})$ as $\int_T \epsilon(t_{\mathrm{res}}) dt_{\mathrm{res}} = \epsilon_{\mathrm{dn}}$, it can be integrated in the PDF as</div><div class="clear"></div>
<div class="linenb">551</div><div class="codeline"><span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">552</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\label</span>{eq:juno:juno:tim_like:dn}</div><div class="clear"></div>
<div class="linenb">553</div><div class="codeline">&nbsp;&nbsp;p(t_{\mathrm{res}}) = (1-\epsilon_{\mathrm{dn}}) \cdot g(t_{\mathrm{res}}) + \epsilon(t_{\mathrm{res}})</div><div class="clear"></div>
<div class="linenb">554</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">555</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">556</div><div class="codeline">The distribution of the residual time $t_{\mathrm{res}}$ of an event can then be compared to $p(t_{\mathrm{res}})$ and the best fitting vertex $\vec{r}_0$ and $t_0$ can be chosen by minimizing</div><div class="clear"></div>
<div class="linenb">557</div><div class="codeline"><span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">558</div><div class="codeline">&nbsp;&nbsp;\mathcal{L}(\vec{r}_0, t_0) = - \mathrm{ln} \bigg(\prod_i p(t^i_{\mathrm{res}}) \bigg)</div><div class="clear"></div>
<div class="linenb">559</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">560</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">561</div><div class="codeline">The parameter of Eq.\ \ref{eq:juno:juno:tim_like:dn} can be measured experimentally. The results shown in Figure \ref{fig:juno:rec:time_likelihood} used PDF from Monte Carlo simulation. The results show that $R_{rec} - R_{true}$ is biased depending on the energy. While this could be corrected using calibration, another algorithm based on charge likelihood was developed to correct this problem.</div><div class="clear"></div>
<div class="linenb">562</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">563</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[ht]</div><div class="clear"></div>
<div class="linenb">564</div><div class="codeline">&nbsp;&nbsp;\centering</div><div class="clear"></div>
<div class="linenb">565</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\includegraphics</span>[width=\linewidth]{images/juno/reco/time_likelihood_results.png}</div><div class="clear"></div>
<div class="linenb">566</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\caption</span>{Bias of the reconstructed radius R (left), $\theta$ (middle) and $\phi$ (right) for multiple energies by the time likelihood algorithm.}</div><div class="clear"></div>
<div class="linenb">567</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\label</span>{fig:juno:rec:time_likelihood}</div><div class="clear"></div>
<div class="linenb">568</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">569</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">570</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">571</div><div class="codeline"><span class="keyword1">\subsubsection</span>{Charge likelihood algorithm}</div><div class="clear"></div>
<div class="linenb">572</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">573</div><div class="codeline">Similarly to the time likelihood algorithms that use a timing PDF, the charge likelihood algorithm use a PE PDF for each PMT depending on the energy and position of the event. With $\mu(\vec{r}_0, E)$ the mean expected number of PE detected by each PMT, the probability to observe $N_{pe}$ in a PMT follow a Poisson distribution. Thus</div><div class="clear"></div>
<div class="linenb">574</div><div class="codeline"><span class="keyword2">\begin{itemize}</span></div><div class="clear"></div>
<div class="linenb">575</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\item</span> The probability to observe no hit ($N_{pe} = 0$) in the $j$-th PMT is $P^{j}_{nohit} (\vec{r}_0, E) = e^{-\mu_j}$</div><div class="clear"></div>
<div class="linenb">576</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\item</span> The probability to observe $N_{pe} \neq 0$ in the $i$-th PMT is $P^{i}_{hit} (\vec{r}_0, E) = \frac{\mu^{N^i_{pe}} e^{-\mu_i}}{N^i_{pe}!}$</div><div class="clear"></div>
<div class="linenb">577</div><div class="codeline"><span class="keyword2">\end{itemize}</span></div><div class="clear"></div>
<div class="linenb">578</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">579</div><div class="codeline">Therefore, the probability to observe a specific hit pattern can be expressed as</div><div class="clear"></div>
<div class="linenb">580</div><div class="codeline"><span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">581</div><div class="codeline">&nbsp;&nbsp;P(\vec{r}_0, E) = \prod_j P^j_{nohit}(\vec{r}_0, E) \cdot \prod_i P^i_{hit}(\vec{r}_0, E)</div><div class="clear"></div>
<div class="linenb">582</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">583</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">584</div><div class="codeline">The best fit values of $\vec{R}_0$ and $E$ can then be calculated by minimizing the negative log-likelihood</div><div class="clear"></div>
<div class="linenb">585</div><div class="codeline"><span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">586</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\label</span>{eq:juno:rec:charge_likelihood}</div><div class="clear"></div>
<div class="linenb">587</div><div class="codeline">&nbsp;&nbsp;\mathcal{L}(\vec{r}_0, E) = - \mathrm{ln}(P(\vec{r}_0,E))</div><div class="clear"></div>
<div class="linenb">588</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">589</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">590</div><div class="codeline">In principle, $\mu_i(\vec{r}_0, E)$ could be expressed</div><div class="clear"></div>
<div class="linenb">591</div><div class="codeline"><span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">592</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\label</span>{eq:juno:rec:mu_i}</div><div class="clear"></div>
<div class="linenb">593</div><div class="codeline">&nbsp;&nbsp;\mu_i(\vec{r}_0, E) = Y \cdot \frac{\Omega(\vec{r}_0, r_i)}{4 \pi} \cdot \epsilon_i \cdot f(\theta_i) \cdot e^{-\sum_m \frac{d_m}{\zeta_m}}\cdot E + \delta_i</div><div class="clear"></div>
<div class="linenb">594</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">595</div><div class="codeline">where $Y$ is the energy scale factor, $\Omega(\vec{r}_0, r_i)$ is the solid angle of the $i$-th PMT, $\epsilon_i$ is its detection efficiency, $f(\theta_i)$ its angular response, $\zeta_m$ is the attenuation length in the materials and $\delta_i$ the expected number of dark noise.</div><div class="clear"></div>
<div class="linenb">596</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">597</div><div class="codeline">However, Eq.\ \ref{eq:juno:rec:mu_i} assume that the scintillation light yield is linear with energy and describe poorly the contribution of indirect light, shadow effect due to the supporting structure and the total reflection effects. The solution is to use data driven methods to produce the Probability Density Function (PDF) by using the calibrations sources and position described in Section \ref{sec:juno:calib}. In the results presented in Figures \ref{fig:juno:rec:time_charge_results}, the PDF was produced using MC simulation and 29 specific calibrations position \cite{li_event_2021} along the Z-axis of the detector.</div><div class="clear"></div>
<div class="linenb">598</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[ht]</div><div class="clear"></div>
<div class="linenb">599</div><div class="codeline">&nbsp;&nbsp;\centering</div><div class="clear"></div>
<div class="linenb">600</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\begin{subfigure}</span>[b]{0.48\linewidth}</div><div class="clear"></div>
<div class="linenb">601</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;\centering</div><div class="clear"></div>
<div class="linenb">602</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\includegraphics</span>[width=\textwidth]{images/juno/reco/charge_likelihood_res.png}</div><div class="clear"></div>
<div class="linenb">603</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\end{subfigure}</span></div><div class="clear"></div>
<div class="linenb">604</div><div class="codeline">&nbsp;&nbsp;\hfill</div><div class="clear"></div>
<div class="linenb">605</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\begin{subfigure}</span>[b]{0.48\linewidth}</div><div class="clear"></div>
<div class="linenb">606</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;\centering</div><div class="clear"></div>
<div class="linenb">607</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\includegraphics</span>[width=\textwidth]{images/juno/reco/charge_likelihood_bias.png}</div><div class="clear"></div>
<div class="linenb">608</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\end{subfigure}</span></div><div class="clear"></div>
<div class="linenb">609</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\caption</span>{<span class="keyword1">\textbf</span>{On the left:} Resolution of the reconstructed R as a function of the energy in the TR area ($R^3 &gt; 4000 \mathrm{m}^3 \equiv R &gt; 16 m$) by the charge and time likelihood algorithms. <span class="keyword1">\textbf</span>{On the right:} Bias of the reconstructed R in the TR area for different energies by the charge likelihood algorithm.}</div><div class="clear"></div>
<div class="linenb">610</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\label</span>{fig:juno:rec:time_charge_results}</div><div class="clear"></div>
<div class="linenb">611</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">612</div><div class="codeline">We see that the charge likelihood algorithm show little bias in the TR area and a better resolution than the time likelihood. The Figure \ref{fig:juno:rec:all_class} shows the radial resolution of the different algorithm presented for this section, we can see the refinement at each step and that the charge likelihood yield the best results.</div><div class="clear"></div>
<div class="linenb">613</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">614</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[ht]</div><div class="clear"></div>
<div class="linenb">615</div><div class="codeline">&nbsp;&nbsp;\centering</div><div class="clear"></div>
<div class="linenb">616</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\includegraphics</span>[height=6cm]{images/juno/reco/vertex_reco_classique.png}</div><div class="clear"></div>
<div class="linenb">617</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\caption</span>{Radial resolution of the different vertex reconstruction algorithms as a function of the energy.}</div><div class="clear"></div>
<div class="linenb">618</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\label</span>{fig:juno:rec:all_class}</div><div class="clear"></div>
<div class="linenb">619</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">620</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">621</div><div class="codeline">The charge based likelihood algorithms already give use some information on the energy as Eq.\ \ref{eq:juno:rec:charge_likelihood} is minimized, but the energy can be further refined as shown in the next section.</div><div class="clear"></div>
<div class="linenb">622</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">623</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">624</div><div class="codeline"><span class="keyword1">\subsection</span>{Energy reconstruction}</div><div class="clear"></div>
<div class="linenb">625</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">626</div><div class="codeline">As explained in Section \ref{sec:juno:nom_precise_measurement}, energy resolution is crucial for the NMO and oscillation parameters measurements. Thus, the energy reconstruction algorithm should take into consideration as much detector effect as possible. The following method is a data driven method based on calibration samples inspired by the charge likelihood algorithm described above \cite{huang_data-driven_2023}.</div><div class="clear"></div>
<div class="linenb">627</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">628</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">629</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[ht]</div><div class="clear"></div>
<div class="linenb">630</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\begin{subfigure}</span>[b]{0.48\linewidth}</div><div class="clear"></div>
<div class="linenb">631</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;\centering</div><div class="clear"></div>
<div class="linenb">632</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\includegraphics</span>[height=6cm]{images/juno/spherical_coordinate_system.png}</div><div class="clear"></div>
<div class="linenb">633</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\caption</span>{Spherical coordinate system used in JUNO for reconstruction.}</div><div class="clear"></div>
<div class="linenb">634</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\label</span>{fig:juno:rec:corrdinate_system}</div><div class="clear"></div>
<div class="linenb">635</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\end{subfigure}</span></div><div class="clear"></div>
<div class="linenb">636</div><div class="codeline">&nbsp;&nbsp;\hfill</div><div class="clear"></div>
<div class="linenb">637</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\begin{subfigure}</span>[b]{0.48\linewidth}</div><div class="clear"></div>
<div class="linenb">638</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;\centering</div><div class="clear"></div>
<div class="linenb">639</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\includegraphics</span>[height=6cm]{images/juno/reco/energy_reco_vars.png}</div><div class="clear"></div>
<div class="linenb">640</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\caption</span>{Definition of the variables used in the energy reconstruction.}</div><div class="clear"></div>
<div class="linenb">641</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\label</span>{fig:juno:rec:energy_vars}</div><div class="clear"></div>
<div class="linenb">642</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\end{subfigure}</span></div><div class="clear"></div>
<div class="linenb">643</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\caption</span>{}</div><div class="clear"></div>
<div class="linenb">644</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">645</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">646</div><div class="codeline"><span class="keyword1">\subsubsection</span>{Charge estimation}</div><div class="clear"></div>
<div class="linenb">647</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">648</div><div class="codeline">The most important element in the energy reconstruction is $\mu_i(\vec{r}_0, E)$ described in Eq.\ \ref{eq:juno:rec:mu_i}. For realistic cases, we also need to take into account the electronics effect that were omitted in the previous section. Those effect will cause a charge smearing due to the uncertainties in the $N_{pe}$ reconstruction. Thus, we define $\hat{\mu}^L(\vec{r}_0, E)$ which is the expected $N_{pe}/E$ in the whole detector for an event with visible energy $E_{vis}$ and position $\vec{r}_0$. The position of the event and PMTs are now defined using $(r, \theta, \theta_{pmt})$ as defined in Figure \ref{fig:juno:rec:energy_vars}.</div><div class="clear"></div>
<div class="linenb">649</div><div class="codeline"><span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">650</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\label</span>{eq:juno:reco:charge_est}</div><div class="clear"></div>
<div class="linenb">651</div><div class="codeline">&nbsp;&nbsp;\hat{\mu}(r, \theta, \theta_{pmt}, E_{vis}) = \frac{1}{E_{vis}} \frac{1}{M} \sum_i^M\frac{\frac{\bar{q}_i}{\hat{Q}_i} - \mu_i^D}{\mathrm{DE}_i}, ~ \mu_i^D = \mathrm{DNR}_i \cdot L</div><div class="clear"></div>
<div class="linenb">652</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">653</div><div class="codeline">where<span class="highlight" title="The personal pronoun 'I' should be uppercase.. Suggestions: [I] (38723) [lt:en:I_LOWERCASE]"> $i$</span> runs over the PMTs with the same $\theta_{pmt}$, $\mathrm{DE}_i$ is the detection efficiency of the $i$-th PMT. $\mu_i^D$ is the expected number of dark noise photoelectrons in the time window $L$. The time window have been optimized to $L = 280 ~ \mathrm{ns}$ \cite{huang_data-driven_2023}. $\bar{q}_i$ is the average recorded photoelectrons in the time window and $\hat{Q}_i$ is the expected average charge for 1 photoelectron. The $N_{pe}$ map is constructed following the procedure described in \cite{huang_improving_2021}.</div><div class="clear"></div>
<div class="linenb">654</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">655</div><div class="codeline"><span class="keyword1">\subsubsection</span>{Time estimation}</div><div class="clear"></div>
<div class="linenb">656</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">657</div><div class="codeline">The second important observable is the hit time of photons that was previously defined in Eq.\ \ref{eq:juno:rec:t_res}. It is here refined as</div><div class="clear"></div>
<div class="linenb">658</div><div class="codeline"><span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">659</div><div class="codeline">&nbsp;&nbsp;t_r = t_h - \mathrm{tof} - t_0 = t_{LS} + t_{TT}</div><div class="clear"></div>
<div class="linenb">660</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">661</div><div class="codeline">where $t_h$ is the time of hit, $t_{LS}$ is the scintillation time and $t_{TT}$ the transit time of PMTs that is described by a Gaussian</div><div class="clear"></div>
<div class="linenb">662</div><div class="codeline"><span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">663</div><div class="codeline">&nbsp;&nbsp;t_{TT} = \mathcal{N}(\overline{\mu_{TT} + t_{d}}, \sigma_{TT})</div><div class="clear"></div>
<div class="linenb">664</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">665</div><div class="codeline">where $\mu_{TT}$ is the mean transit time in PMTs, $\sigma_{TT}$ is the Transit Time Spread (TTS) of the PMTs and $t_{d}$ is the delay time in the electronics. The effective refraction index of the LS is also corrected to take into account the propagation distance in the detector.</div><div class="clear"></div>
<div class="linenb">666</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">667</div><div class="codeline">The timing PDF $P_T(t_r | r,d,\mu_l,\mu_d,k)$ can now be generated using calibration sources \cite{huang_data-driven_2023}. This PDF describes the probability that the residual time of the first photon hit is in $[t_r, t_r + \delta]$ with $r$ the radius of the event vertex, $d = |\vec{r} - \vec{r}_{PMT}|$ the propagation distance, $\mu_l$ and $\mu_d$ the expected number of PE and dark noise in the electronic reading window and $k$ is the detected number of PE.</div><div class="clear"></div>
<div class="linenb">668</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">669</div><div class="codeline">Now let denote $f(t, r, d)$ the probability density function of ``photoelectron hit a time t'' for an event happening at $r$ where the photons traveled the distance $d$ in the LS</div><div class="clear"></div>
<div class="linenb">670</div><div class="codeline"><span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">671</div><div class="codeline">&nbsp;&nbsp;F(t, r, d) = \int_t^L f(t', r, d)dt'</div><div class="clear"></div>
<div class="linenb">672</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">673</div><div class="codeline">Based on the PDF for one photon $k=1$, one can define</div><div class="clear"></div>
<div class="linenb">674</div><div class="codeline"><span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">675</div><div class="codeline">&nbsp;&nbsp;P^l_T(t|k=n) = I^l_n [f_l(t)F^{n-1}_l(t)]</div><div class="clear"></div>
<div class="linenb">676</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">677</div><div class="codeline">where the indicator $l$ means that the photons comes from the LS and $I^l_n$ a normalization factor. To this PDF we add the probability to have photons coming from the dark noise indicated by the indicator $d$ using</div><div class="clear"></div>
<div class="linenb">678</div><div class="codeline"><span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">679</div><div class="codeline">&nbsp;&nbsp;f_d(t) = 1 / L, ~ F_d(t) = 1 - \frac{t}{L}</div><div class="clear"></div>
<div class="linenb">680</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">681</div><div class="codeline">and so for the case where only one photon is detected by the PMT ($k=1$)</div><div class="clear"></div>
<div class="linenb">682</div><div class="codeline"><span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">683</div><div class="codeline">&nbsp;&nbsp;P_T(t|\mu_l, \mu_d, k = 1) = I_1 [ P(1, \mu_l) P(0, \mu_d) f_l(t) + P(0, \mu_l) P(1, \mu_d) f_d(t) ]</div><div class="clear"></div>
<div class="linenb">684</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">685</div><div class="codeline">where $P(k_\alpha, \mu_\alpha)$ is the Poisson probability to detect $k_\alpha$ PE from $\alpha \in \{l, d\}$ with the condition $k_l + k_d = k$.</div><div class="clear"></div>
<div class="linenb">686</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">687</div><div class="codeline">Now that we have the individual timing and charge probability we can construct the charge likelihood referred as QMLE:</div><div class="clear"></div>
<div class="linenb">688</div><div class="codeline"><span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">689</div><div class="codeline">&nbsp;&nbsp;\mathcal{L}(q_1, q_2, ..., q_N | \vec{r}, E_{vis}) = \prod_{j \in \mathrm{unfired}} e^{-\mu_j} \prod_{i \in \mathrm{fired}} \bigg(\sum_{k=1} P_Q(q_i|k) \cdot P(k, \mu_i) \bigg)</div><div class="clear"></div>
<div class="linenb">690</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">691</div><div class="codeline">where $\mu_i = E_{vis} \hat{\mu_i^L} + \mu_i^D$ and $P(k, \mu_i)$ is the Poisson probability of observing k PE. $P_Q(q_i|k)$ is the charge PDF for $k$ PE. And we can also construct the time likelihood referred as TMLE:</div><div class="clear"></div>
<div class="linenb">692</div><div class="codeline"><span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">693</div><div class="codeline">&nbsp;&nbsp;\mathcal{L}(t_{1,r}, t_{2,r}, ..., t_{N,r} | \vec{r}, t_0) = \prod_{i \in \mathrm{hit}} \frac{\sum_{k=1}^K P_T(t_{i,r} | r, d, \mu_i^l, \mu_i^d, k) \cdot P(k, \mu^l_i + \mu^d_i)}{\sum_{k=1}^K P(k, \mu^l_i + \mu^d_i)}</div><div class="clear"></div>
<div class="linenb">694</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">695</div><div class="codeline">where $K$ is cut to 20 PE and <span class="highlight" title="Possible agreement error. The noun 'hit' seems to be countable.. Suggestions: [hits] (40843) [lt:en:CD_NN]">hit</span> is the set of hits satisfying $-100 &lt; t_{i,r} &lt; 500$ ns.</div><div class="clear"></div>
<div class="linenb">696</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">697</div><div class="codeline">Merging those two likelihood give the charge-time likelihood QTMLE, the core algorithm of OMILREC.</div><div class="clear"></div>
<div class="linenb">698</div><div class="codeline"><span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">699</div><div class="codeline">&nbsp;&nbsp;\mathcal{L}(q_1, q_2, ..., q_N; t_{1,r}, t_{2,r}, ..., t_{N,r} | \vec{r}, t_0 , E_{vis}) = \mathcal{L}(q_1, q_2, ..., q_N | \vec{r}, E_{vis}) \cdot \mathcal{L}(t_{1,r}, t_{2,r}, ..., t_{N,r} | \vec{r}, t_0)</div><div class="clear"></div>
<div class="linenb">700</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">701</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">702</div><div class="codeline">The radial and energy resolutions of the different likelihood are presented in Figure \ref{fig:juno:rec:qtmle} (from \cite{huang_data-driven_2023}). We can see the improvement of adding the time information to the vertex reconstruction and that an increase in vertex precision can bring improvement in the energy resolution, especially at low energies.</div><div class="clear"></div>
<div class="linenb">703</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">704</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[ht]</div><div class="clear"></div>
<div class="linenb">705</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\begin{subfigure}</span>{0.48\linewidth}</div><div class="clear"></div>
<div class="linenb">706</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;\centering</div><div class="clear"></div>
<div class="linenb">707</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\includegraphics</span>[width=\textwidth]{images/juno/reco/radial_qtmle.png}</div><div class="clear"></div>
<div class="linenb">708</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\caption</span>{Radial resolutions of the likelihood-based algorithm TMLE, QMLE and QTMLE.}</div><div class="clear"></div>
<div class="linenb">709</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\end{subfigure}</span></div><div class="clear"></div>
<div class="linenb">710</div><div class="codeline">&nbsp;&nbsp;\hfill</div><div class="clear"></div>
<div class="linenb">711</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\begin{subfigure}</span>{0.48\linewidth}</div><div class="clear"></div>
<div class="linenb">712</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;\centering</div><div class="clear"></div>
<div class="linenb">713</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\includegraphics</span>[width=\textwidth]{images/juno/reco/energy_qtmle.png}</div><div class="clear"></div>
<div class="linenb">714</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\caption</span>{Energy resolution of QMLE and QTMLE using different vertex resolutions.}</div><div class="clear"></div>
<div class="linenb">715</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\end{subfigure}</span></div><div class="clear"></div>
<div class="linenb">716</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\caption</span>{}</div><div class="clear"></div>
<div class="linenb">717</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\label</span>{fig:juno:rec:qtmle}</div><div class="clear"></div>
<div class="linenb">718</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">719</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">720</div><div class="codeline">Data driven methods prove to be performant in the energy and vertex reconstruction given that we have enough calibrations sources to produce the PDF. In addition to this, member of JUNO have developed ML algorithms for reconstruction. The one focused on IBD reconstruction are presented in the next section.</div><div class="clear"></div>
<div class="linenb">721</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">722</div><div class="codeline"><span class="keyword1">\subsection</span>{Machine learning for reconstruction}</div><div class="clear"></div>
<div class="linenb">723</div><div class="codeline"><span class="keyword1">\label</span>{sec:juno:ml}</div><div class="clear"></div>
<div class="linenb">724</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">725</div><div class="codeline">The power of ML is the ability to model complex response to a specific problem. In JUNO the reconstruction problematic can be expressed as follows: knowing that each PMT, large or small, detected a given number of PE $Q$ at a given time $t$ and their position is<span class="highlight-sh" title="There should be a space after a comma. [sh:d:001]"><span class="highlight-sh" title="There should be a space after a comma. [sh:d:001]"><span class="highlight" title="Put a space after the comma.. Suggestions: [, y] (41897) [lt:en:COMMA_PARENTHESIS_WHITESPACE]"> $x,y,z$</span></span></span>, where was the energy deposited? And how much energy was it? The NN will model a function that naively goes:</div><div class="clear"></div>
<div class="linenb">726</div><div class="codeline"><span class="keyword2">\begin{equation}</span></div><div class="clear"></div>
<div class="linenb">727</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;\mathbb{R}^{5 \times N_{pmt}} \longmapsto \mathbb{R}^4</div><div class="clear"></div>
<div class="linenb">728</div><div class="codeline"><span class="keyword2">\end{equation}</span></div><div class="clear"></div>
<div class="linenb">729</div><div class="codeline">It is worth pointing that while this is already a lot in information, this is not the rawest representation of the experiment. We could indeed replace the charge and time by the waveform in the time window of the event, but that would lead to an input representation size that would exceed our computational limits. Also, due to those computational limits, most of the ML algorithm reduce this input phase space either by structurally encoding the information (pictures, graph), by aggregating it (mean, variance, $\ldots$) or by exploiting invariance and equivariance of the experiment (rotational invariance due to the sphericity, $\ldots$).</div><div class="clear"></div>
<div class="linenb">730</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">731</div><div class="codeline">For machine learning to converge to performant algorithm, a large dataset exploring all the phase space of interest is needed. For the following studies, data from the Monte Carlo simulation presented in Section \ref{sec:juno:software} are used for training. When the detector will be finished, data from calibrations sources will additionally be used.</div><div class="clear"></div>
<div class="linenb">732</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">733</div><div class="codeline"><span class="keyword1">\subsubsection</span>{Boosted Decision Tree (BDT)}</div><div class="clear"></div>
<div class="linenb">734</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">735</div><div class="codeline">One of the most classic ML method used in physics in last years is the Boosted Decision Tree. They have been explored for vertex reconstruction \cite{qian_vertex_2021} and for energy reconstruction \cite{qian_vertex_2021, gavrikov_energy_2022}.</div><div class="clear"></div>
<div class="linenb">736</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">737</div><div class="codeline">For vertex and energy reconstruction a BDT was developed using the aggregated information presented in \ref{tab:juno:rec:bdt_vertex}.</div><div class="clear"></div>
<div class="linenb">738</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">739</div><div class="codeline"><span class="keyword2">\begin{table}</span>[ht]</div><div class="clear"></div>
<div class="linenb">740</div><div class="codeline">&nbsp;&nbsp;\centering</div><div class="clear"></div>
<div class="linenb">741</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\begin{tabular}</span>{l|r}</div><div class="clear"></div>
<div class="linenb">742</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;Parameter &amp; description \\</div><div class="clear"></div>
<div class="linenb">743</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;\hline</div><div class="clear"></div>
<div class="linenb">744</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;$nHits$ &amp; Total number of hits \\</div><div class="clear"></div>
<div class="linenb">745</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;$x_{cc}, y_{cc}, z_{cc}, R_{cc}$ &amp; Coordinates of the center of charge \\</div><div class="clear"></div>
<div class="linenb">746</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;$ht_{mean}, ht_{std}$ &amp; Hit time mean and standard deviation</div><div class="clear"></div>
<div class="linenb">747</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\end{tabular}</span></div><div class="clear"></div>
<div class="linenb">748</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\caption</span>{Features used by the BDT for vertex reconstruction.}</div><div class="clear"></div>
<div class="linenb">749</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\label</span>{tab:juno:rec:bdt_vertex}</div><div class="clear"></div>
<div class="linenb">750</div><div class="codeline"><span class="keyword2">\end{table}</span></div><div class="clear"></div>
<div class="linenb">751</div><div class="codeline">Its reconstruction performances are presented in Figure \ref{fig:juno:rec:ml_res}.</div><div class="clear"></div>
<div class="linenb">752</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">753</div><div class="codeline">A second and more advanced BDT, subsequently named BDTE, that only reconstruct energy use a different set of features \cite{gavrikov_energy_2022}. They are presented in Table \ref{tab:juno:rec:bdte}</div><div class="clear"></div>
<div class="linenb">754</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">755</div><div class="codeline"><span class="keyword2">\begin{table}</span></div><div class="clear"></div>
<div class="linenb">756</div><div class="codeline">&nbsp;&nbsp;\centering</div><div class="clear"></div>
<div class="linenb">757</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\begin{tabular}</span>{|c|c|}</div><div class="clear"></div>
<div class="linenb">758</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;\hline</div><div class="clear"></div>
<div class="linenb">759</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;AccumCharge &amp;  $ht_{5\%-2\%}$ \\</div><div class="clear"></div>
<div class="linenb">760</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;$R_{cht}$ &amp; $pe_{mean}$ \\</div><div class="clear"></div>
<div class="linenb">761</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;$z_{cc}$ &amp; $J_{cht}$ \\</div><div class="clear"></div>
<div class="linenb">762</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;$pe_{std}$ &amp; $\phi_{cc}$ \\</div><div class="clear"></div>
<div class="linenb">763</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;nPMTs &amp;  $ht_{35\%-30\%}$\\</div><div class="clear"></div>
<div class="linenb">764</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;$ht_{kurtosis}$ &amp; $ht_{20\%-15\%}$ \\</div><div class="clear"></div>
<div class="linenb">765</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;$ht_{25\%-20\%}$ &amp; $pe_{35\%}$ \\</div><div class="clear"></div>
<div class="linenb">766</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;$R_{cc}$ &amp; $ht_{30\%-25\%}$ \\</div><div class="clear"></div>
<div class="linenb">767</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;\hline</div><div class="clear"></div>
<div class="linenb">768</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">769</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\end{tabular}</span></div><div class="clear"></div>
<div class="linenb">770</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\caption</span>{Features used by the BDTE algorithm. $pe$ and $ht$ reference the charge and hit-time distribution respectively and the percentages are the quantiles of those distributions. $cht$ and $cc$ reference the barycenters of hit time and charge respectively.}</div><div class="clear"></div>
<div class="linenb">771</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\label</span>{tab:juno:rec:bdte}</div><div class="clear"></div>
<div class="linenb">772</div><div class="codeline"><span class="keyword2">\end{table}</span></div><div class="clear"></div>
<div class="linenb">773</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">774</div><div class="codeline"><span class="keyword1">\subsubsection</span>{Neural Network (NN)}</div><div class="clear"></div>
<div class="linenb">775</div><div class="codeline">Three type of neural networks have explored for event reconstruction in JUNO Deep Neural Network (DNN), Convolutional Neural Network (CNN) and Graph Network (GNN).</div><div class="clear"></div>
<div class="linenb">776</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">777</div><div class="codeline">The CNN are using 2D projection of the detector representing it as an image with two channels, one for the charge $Q$ and one for the time $t$. The position of the PMTs is structurally encoded in the pixel containing the information of this PMT. In \cite{qian_vertex_2021}, the pixel is chosen based on a transformation of $\theta$ and $\phi$ coordinates to the 2D plane and rounded to the nearest pixel. Sufficiently large dimension has been selected to prevent two PMTs to be located in the same pixel. An example of this projection can be found in Figure \ref{fig:juno:rec:cnn_proj}. The performances of the CNN can be found in Figure \ref{fig:juno:rec:ml_res}.</div><div class="clear"></div>
<div class="linenb">778</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">779</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[ht]</div><div class="clear"></div>
<div class="linenb">780</div><div class="codeline">&nbsp;&nbsp;\centering</div><div class="clear"></div>
<div class="linenb">781</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\includegraphics</span>[width=\linewidth]{images/juno/reco/cnn_proj.png}</div><div class="clear"></div>
<div class="linenb">782</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\caption</span>{Projection of the LPMTs in JUNO on a 2D plane. (a) Show the distribution of all PMTs and (b) and (c) are example of what the charge and time channel looks like respectively.}</div><div class="clear"></div>
<div class="linenb">783</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\label</span>{fig:juno:rec:cnn_proj}</div><div class="clear"></div>
<div class="linenb">784</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">785</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">786</div><div class="codeline">Using 2D have the upside of encoding a large part of the information structurally but loose the rotational invariance of the detector. It also gives undefined information to the neural network (what is a pixel without PMT? What should be its charge and time?), cause deformation in the representation of the detector (sides of projection) and lose topological information.</div><div class="clear"></div>
<div class="linenb">787</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">788</div><div class="codeline">One of the way to present structurally the sphericity of JUNO to a NN is to use a graph: A collection of objects $V$ called nodes and relations $E$ called edges, each relation associated to a couple ${v_1, v_2}$ forming the graph $G(E, V)$. Nodes and edges can hold information or features. In \cite{qian_vertex_2021} the nodes, are geometrical region of the detector as defined by the HealPix \cite{gorski_healpix_2005-1}. The features of the nodes are aggregated information from the PMTs it contains. The edges contain geographic information of the nodes relative positions.</div><div class="clear"></div>
<div class="linenb">789</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">790</div><div class="codeline">This data representation has the advantages to keep the topology of the detector intact. It also allows the use of rotational invariant algorithms for the NN, thus taking advantage of the symmetries of the detector.</div><div class="clear"></div>
<div class="linenb">791</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">792</div><div class="codeline">The neural network then processes the graph using Chebyshev Convolutions \cite{defferrard_convolutional_2017}. The performances of the GNN are presented in Figure \ref{fig:juno:rec:ml_res}.</div><div class="clear"></div>
<div class="linenb">793</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">794</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">795</div><div class="codeline"><span class="keyword2">\begin{figure}</span>[ht]</div><div class="clear"></div>
<div class="linenb">796</div><div class="codeline">&nbsp;&nbsp;\centering</div><div class="clear"></div>
<div class="linenb">797</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\begin{subfigure}</span>{0.48\linewidth}</div><div class="clear"></div>
<div class="linenb">798</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;\centering</div><div class="clear"></div>
<div class="linenb">799</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\includegraphics</span>[width=\linewidth]{images/juno/reco/ml_vertex.png}</div><div class="clear"></div>
<div class="linenb">800</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\end{subfigure}</span></div><div class="clear"></div>
<div class="linenb">801</div><div class="codeline">&nbsp;&nbsp;\hfill</div><div class="clear"></div>
<div class="linenb">802</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\begin{subfigure}</span>{0.48\linewidth}</div><div class="clear"></div>
<div class="linenb">803</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;\centering</div><div class="clear"></div>
<div class="linenb">804</div><div class="codeline">&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword1">\includegraphics</span>[width=\linewidth]{images/juno/reco/ml_energy.png}</div><div class="clear"></div>
<div class="linenb">805</div><div class="codeline">&nbsp;&nbsp;<span class="keyword2">\end{subfigure}</span></div><div class="clear"></div>
<div class="linenb">806</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\caption</span>{Radial (left) and energy (right) resolutions of different ML algorithms. The results presented here are from \cite{qian_vertex_2021}. DNN is a deep neural network, BDT is a BDT, ResNet-J and VGG-J are CNN and GNN-J is a GNN.}</div><div class="clear"></div>
<div class="linenb">807</div><div class="codeline">&nbsp;&nbsp;<span class="keyword1">\label</span>{fig:juno:rec:ml_res}</div><div class="clear"></div>
<div class="linenb">808</div><div class="codeline"><span class="keyword2">\end{figure}</span></div><div class="clear"></div>
<div class="linenb">809</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">810</div><div class="codeline">Overall ML algorithms show similar performances as classical algorithms in terms of energy reconstructions with the more complex structure CNN and GNN showing better performances than BDT and DNN. For vertex reconstruction, the BDT and DNN show poor performance while CNN are on the level of the classical algorithms.</div><div class="clear"></div>
<div class="linenb">811</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">812</div><div class="codeline"><span class="keyword1">\section</span>{Conclusion}</div><div class="clear"></div>
<div class="linenb">813</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">814</div><div class="codeline">That these first DL algorithms tried at JUNO to reconstruct IBDs do not outperform the classical method can be explained. They constitute a first exploration of these methods potential, as do the original GNN we describe in Chapter \ref{sec:jgnn}. Indeed, the likelihood method is also based on the full list of the charges ($Q$) and times ($t$) all PMTs, and the PDF's design accounts for an advanced knowledge of the detector (with a lot of human expertise). The fact that the methods presented in this chapter can learn enough from just the<span class="highlight-sh" title="There should be a space after a comma. [sh:d:001]"><span class="highlight" title="Put a space after the comma.. Suggestions: [, t] (46372) [lt:en:COMMA_PARENTHESIS_WHITESPACE]"> $Q,t$</span></span> list, to reach similar performance, is already an interesting result. But this is not decisive yet, in my opinion.</div><div class="clear"></div>
<div class="linenb">815</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">816</div><div class="codeline">Actually, is there hope that one day DL methods reach better results at JUNO than classical's? This is not a trivial question. A possibility would be to let them start from an even rawer level (involving a number of variables which would make a likelihood intractable). This would mean, instead of $Q$ and $t$, the full waveform in each PMT. With such a quantity of input information to analyze to identify patterns, even DL methods can be limited. The choice of architecture is then important, to guide the algorithm towards pertinent features. We doubt whether CNN's would be the best choice here. We bet that GNN's could be better tools, with more flexibility to hierarchize information (the choice of which PMTs to link already helps here, as well as the possible usage of higher order quantities). The first GNN developed in JUNO (described above, \cite{qian_vertex_2021}) does not do that. It's still only based on $(Q,t)$ couples and link only neighbor PMTs in its first layer. It serves essentially as a way to avoid the problems encountered by CNNs due to the planar projection of a spherical image.</div><div class="clear"></div>
<div class="linenb">817</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">818</div><div class="codeline">In Chapter \ref{sec:jgnn}, we tried an original GNN architecture. The goal was not yet to include a rawer information, but to see if this architecture would perform as well as the one described above when using $Q$'s and $t$'s as the rawest information. If so, then there is hope that when rawer information will be included, this original architecture will be able to perform even better.</div><div class="clear"></div>
<div class="linenb">819</div><div class="codeline"></div><div class="clear"></div>
<div class="linenb">820</div><div class="codeline"><span class="keyword2">\end{document}</span></div><div class="clear"></div>
</div>
<hr/>
Output produced by TeXtidote v0.8.4, &copy; 2018-2022 Sylvain Hall&eacute; - All rights reserved.<br/>
See the <a href="https://sylvainhalle.github.io/textidote">TeXtidote website</a> for more information.
</body>
</html>
